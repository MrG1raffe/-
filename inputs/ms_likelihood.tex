\documentclass[../TV&MS.tex]{subfiles}
\begin{document}

\subsection{Функция правдоподобия}

Вот мы рассмотрели оценки матожидания и дисперсии.
Они хорошие: несмещённые, состоятельные и вообще милашки.
Но что если нам нужны не они? Откуда можно брать оценки?
Для этого придумали функцию правдоподобия. 
Сначала дадим пацанское определение функции правдоподобия,
потом поковыряем парочку простых примеров, потом поймём, 
что с пацанским определением возникают некоторые проблемы,
и дадим страшное и жуткое определение через лютый функан.
Погнали!

\begin{Def}\label{ms:l:def:likelihood}
    Пусть дана выборка $\Smpl = (X_1,\ldots X_n)$ из распределения с
    плотностью $p(x, \theta)$, где $\theta \in \Theta$~---~параметр.
    Тогда \mdef{функцией правдоподобия} называется произведение плотностей.
    $$
        L(\Smpl, \theta) \myeq \prod\limits_{i=1}^{n} p(X_i, \theta).
    $$
\end{Def} 

\begin{Wtf}
    Жизненный смысл функции правдоподобия такой: вероятность наблюдать то,
    что мы наблюли. Как ей пользоваться?
    Для начала отметим, что эта вероятность зависит от параметра.
    Тогда мы говорим, что параметр в распределении такой,
    что вероятность наблюдать то, что мы наблюли, наибольшая.
    То есть, кто мы такие, чтобы наблюдать редкие события?
    Да никто! Недостойны мы такой чести.
    Поэтому полагаем параметр таким, что событие $\Smpl$ наиболее вероятное.
\end{Wtf} 

\begin{Ex}
    Пусть $X_i \sim \Norm(\theta, 1)$. Мы хотим оценить матожидание.
    Запишем функцию правдоподобия:
    \begin{equation}
        L(\Smpl, \theta) = \prod\limits_{i=1}^{n} p(X_i, \theta) =
        \prod\limits_{i=1}^{n} \frac{1}{\sqrt{2\pi}} exp \left\{ -\frac{(X_i - \theta)^2}{2} \right\}
    .\end{equation} 
    Дальше надо её максимизировать по $\theta$,
    но работать с произведением~---~себя не уважать, 
    поэтому будем максимизировать не саму функцию правдоподобия, а её логарифм.
    Тут все законно, потому что логарифм~---~монотонная функция,
    и максимум логарифма достигается при том же $\theta$, при котором достигается максимум самой функции правдоподобия.
    Да и вообще, первое, что обычно делают с функцией правдоподобия~---~
    берут от неё логарифм и произведение становится суммой.
    \begin{equation}
        \ln{L(\Smpl, \theta)} = 
        - \sum\limits_{i=1}^{n} \frac{(X_i - \theta)^2}{2} + const
    .\end{equation} 
    В $const$ мы запихали сумму логарифмов $\frac{1}{\sqrt{2\pi}}$.
    Все равно мы будем сейчас максимизировать (= брать производную)
    по $\theta$ и все константы убьются.
    \begin{equation}
            \frac{d}{d\theta} L(\Smpl, \theta) = 0 \iff
            \sum\limits_{i=1}^{n} (X_i - \theta) = 0 \iff
            \theta = \frac{1}{n} \sum\limits_{i=1}^{n} X_i
    .\end{equation} 
    Паразительно! Оценили матожидание с помощью функции правдоподобия и получили выборочное матожидание.
    Кстати, параметр $\theta$, на котором достигается максимум функции правдоподобия,
    обычно обозначают $\theta_{ML}$, от слов <<maximum likelihood>>.
\end{Ex} 

\begin{Ex}
    Теперь пусть $X_i \sim \Norm(a, \theta^2)$.
    Попробуем теперь кастануть ММП (метод максимального правдоподобия).
    \begin{equation}
        \begin{split}
            L(\Smpl, \theta) &= \prod\limits_{i=1}^{n}\frac{1}{\theta\sqrt{2\pi}}  exp \left\{ -\frac{(X_i-a)^2}{2\theta^2} \right\} \\
            \frac{d}{d\theta} \ln{L(\Smpl, \theta)} &=
            -\sum\limits_{i=1}^{n} \frac{1}{\theta} 
            + \sum\limits_{i=1}^{n} \frac{(X_i-a)^2}{\theta^3} \\
            \left. \frac{d}{d\theta} \ln{L(\Smpl, \theta)} \right|_{\theta = \theta_{ML}}&= 0 \implies
            \theta_{ML} = \frac{1}{n} \sum\limits_{i=1}^{n} (X_i - a)^2.
        \end{split} 
    \end{equation} 
\end{Ex} 

Получили выборочную дисперсию. 
Вспомним, что выборочная дисперсия смещённо оценивает теоретическую дисперсию.
Но никто и не обещал, что ММП даёт несмещённые оценки. 
Было бы неплохо в этих двух примерах показать, что мы получили именно максимум, а не какую-то левую стационарную точку, но мы не будем.

\begin{Ex}
    А теперь рассмотрим пример, в котором непонятно, какую оценку брать.
    $X_i \sim U[0, \theta]$~---~равномерное распределени на отрезке, с неизвестным верхним концом.
    Ну по классике:
    \begin{equation}
            L(\Smpl, \theta) =
            \prod\limits_{i=1}^{n} \frac{1}{\theta} \Ind\bigl(X_i \in \left[ 0, \theta \right]\bigr) =
            \theta^{-n}\Ind\left( X_{(n)} \le \theta \right).
    \end{equation} 
    Как мы так упростили произведение индикаторов?
    Так как по условию $X_i$ распределена от $0$ до $\theta$,
    то $X_i \ge 0$ заведомо, и эту часть индикаторов можно выкинуть.
    Теперь произведение индикаторов того, что все $X_i \le \theta$
    равносильно индикатору того, что каждая $X_i \le \theta$,
    а это уже равносильно тому, что максимум не больше $\theta$.
    Переходим к максимизации этого безобразия.
    Тут нельзя просто так взять и продифференцировать из-за индикаторов.
    Попробуем по-другому: тут стоит $\theta^{-n}$. 
    Эта штука большая (максимизируем же), когда $\theta$ мальеньая.
    Но если  $\theta$ будет меньше максимального элемента выборки $X_{(n)}$,
    то вся наша максимизация пойдёт лесом, так как один из индикаторов обнулится.
    Поэтому $\theta_{ML} = X_{(n)}$.
\end{Ex}

Всё, хватит пока примеров. Казалось, бы, всё просто шоколадно,
но что если нам дадут выборку из случайных величин, которые принимают
значения $1$ и $0$ с вероятностями $p$ и $1-p$?
Какую плотнось взять для функции правдоподобия?
Правильный ответ~---~любую удобную нам, для которой интеграл Лебега по считающей мере
по произвольному борелевскому множеству будет выдавать нужные вероятности.
Сейчас введём всю нужную математику, а потом вернёмся к этому примеру и придумаем, как тут быть.

\begin{Def}
    Пусть на измеримом пространстве $\left( \Omega, \Ev \right)$ заданы меры $\mu$ и $\nu$.
    Мера  $\nu$ называется \mdef{абсолюно непрервыной} относительно меры $\mu$, если
    $\forall A \in \Ev,\ \mu\left( A \right) = 0 \mapsto \nu\left( A \right) = 0.$
    Обозначается $\nu \ll \mu$.
\end{Def} 

\begin{Th}[Рад\'{о}на"--~Ник\'{о}дима]
    Если на измеримом пространстве заданы меры $\nu$ и $\mu$ и при этом
    $\nu \ll \mu$, то существует почти всюду единственная измеримая функция
    $X(\omega)$, такая что 
    $$\forall A \in \Ev \mapsto \nu(A) = \int\limits_{A}X(\omega)\mu(d\omega).$$
\end{Th} 

\begin{Wtf}
    Эта теорема обобщает понятие производной на всякие различные кривые функции.
\end{Wtf}
\begin{Why}
    А вот зачем: пусть у нас на измеримом пространстве вдруг задана вероятность событий, причем распределение дискретно.
    А мы хотим что-то оценить методом максимального правдоподобия.
    Тогда теорема говорит, что если мы найдем такую меру $\mu$,
    относительно которой наша вероятностная мера будет абсолютно непрерывна,
    то существует плотность распределения, которая определена однозначно с точностью до значений на множестве $S$, такого что $\mu(S) = 0$.
\end{Why} 

\begin{Def}
    Статистическая структура \mdef{допускает функцию правдоподобия},
    если существует $\mu$, определенная на $\sigma$-алгебре событий  $\Ev$,
    относительно которой вероятностные меры нашей статистической структуры абсолютно непрерывны.
\end{Def}

\begin{Def}
    Пусть задано не более чем счётное число точек $A = \{a_1, \ldots , a_n, \ldots \}$.
    Мера называется \mdef{считающей}, если для любого борелевского множества
    его мера равна числу точек из $A$, принадлежащих этому множеству.
\end{Def}

\begin{Ex}
    Теперь вернёмся к тому примеру с дискретной случайной величиной:
    $\Pro(\xi = 1) = p,\ \Pro(\xi = 0) = 1 - p$.
    Сначала найдем меру, относительно которой вероятностная мера будет абсолютно непрерывна.
    Это будет считающая мера $\mu_A(B)$, где $A = \left\{ 0, 1 \right\}$~---~
    множество, по которому мы будем считаь.
    Эта мера сопоставляет каждому борелевскому множеству число $0$,
    если в него не попала ни одна из точек $\left\{ 0, 1 \right\}$,
    $1$, если попала равно одна из этих точек и $2$, если попали обе точки.
    Проверим условие абсолютной непрерывности.
    Действительно, вероятность только трех событий больше нуля:
    $0$, $1$ и оба сразу.
    Соответственно, вероятностная мера выдаст ноль на тех и только на тех множествах,
    которые не содержат ни одну из этих точек.
    Наша считающая мера выдает ноль на тех же множествах.
    А значит $\forall B \in \Bor$, если $\mu(B) = 0$, то и $\Pro(B) = 0$,
    и вероятностная мера является абсолютно непрерывной относительно меры $\mu$.

    Теперь будем разбираться с правдоподобием.
    По теореме Радона"--~Никодима функция правдоподобия почти всюду единственна.
    В нашем случае почти всюду~---~это в двух точках, мера которых отлична от нуля: $0$ и $1$.
    Причем должно быть выполнено:
     \begin{equation*}
        \begin{cases}
            L(0, p) = 1 - p, \\
            L(1, p) = p,
        \end{cases} 
    \end{equation*}
    чтобы интеграл от неё действительно давал нужную вероятность.
    Лулзов ради накидаем пяток подходящих функций, а потом выберем удобную:
    \begin{subequations}
    \begin{equation}\label{ms:l:eq:l_1}
        L(x, p) = 1 - p + (2p - 1)x,
    \end{equation}
    \begin{equation}\label{ms:l:eq:l_2}
        L(x, p) = p\Ind(x = 1) + (1 - p)\Ind(x = 0)
    \end{equation}
    \begin{equation}\label{ms:l:eq:l_3}
        L(x, p) = (1 - p)\cos\left(\frac{\pi x}{2}\right) + p\sin\left(\frac{\pi x}{2}\right)
    \end{equation}\label{ms:l:eq:l_4}
    \begin{equation}
        L(x, p) = 1 - p + \frac{8p - 4}{\pi}\arctg(x)
    ,\end{equation} 
    \begin{equation}\label{ms:l:eq:l_5}
        L(x, p) = p^{x}(1 - p)^{1-x}
    .\end{equation} 
    \end{subequations} 
    \noindent
    В принципе, все эти функции подойдут, и в случае, когда выборка
    состоит из одногот элемента, можно использовать любую, но пусть у нас теперь $\Smpl = \left( X_1, \ldots , X_n \right)$. 
    Сейчас будет понятно, почему~\eqref{ms:l:eq:l_5}~---~самый удобный вариант.
    \begin{gather}
        L(\Smpl, p) = \prod\limits_{i=1}^{n}p^{X_i}(1-p)^{1-X_i}
        = p^{\sum\limits_{i=1}^{n} X_i}(1-p)^{n - \sum\limits_{i=1}^{n} X_i}\\
        \frac{d}{dp}\ln L(\Smpl, p) = 
        \frac{1}{p} \sum\limits_{i=1}^{n} X_i - \frac{1}{1-p} \left( n - \sum\limits_{i=1}^{n} X_i \right) = 0 \\
        p = \frac{1}{n} \sum\limits_{i=1}^{n} X_i
    .
    \end{gather}
    \noindent
    Получили ту самую оценку МО в схеме бернулли.
    Самые отбитые могут попробовать провернуть это с другой функцией правдоподобия~---~будет долго и больно.
\end{Ex} 

\newpage

\end{document} 
