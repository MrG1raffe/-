\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{bbm} % для индикатора
\usepackage{chngcntr} % без этого пакета у меня не робит counterwithin

\graphicspath{{pictures/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}

\textheight=24cm
\textwidth=16cm
\oddsidemargin=0pt
\topmargin=-1.5cm
\parindent=24pt
\parskip=0pt
\tolerance=2000
\flushbottom

\newtheorem{Th}{Теорема}
\newtheorem{Def}{Определение}
\newtheorem{Lem}{Лемма}
\newtheorem{St}{Утверждение}

\newenvironment{Proof}{\par\noindent{\bf Доказательство}}{$\blacksquare$} 
\newenvironment{Ex}{{\bf Пример}\ }{}
\newenvironment{Wtf}{\includegraphics[height=5mm]{ping}}{}
\newenvironment{Why}{\includegraphics[height= 5mm]{cat}}{}

\numberwithin{Th}{section}
\numberwithin{Def}{section}
\numberwithin{Lem}{section}
\numberwithin{St}{section}
\numberwithin{equation}{section}
\counterwithin*{section}{part}

\newcommand\Set[2]{\left\{ #1 \colon #2 \right\}}
\newcommand\Sum[3]{\sum\limits_{#1 = #2}^{#3}}
\newcommand\Pro{\mathbb{P}} % вероятность
\newcommand\Ev{\mathscr{A}} % алгебра событий
\newcommand\Bor{\mathscr{B}} % борелевская сигма-алгебра
\newcommand\Real{\mathbb{R}} % вещественная прямая
\newcommand\Int{\mathbb{Z}} % целые числа
\newcommand\Nat{\mathbb{N}} % натуральные числа
\newcommand\Expec{\mathbb{E}} % матожидание 
\newcommand\Disp{\mathbb{D}}  % дисперсия
\newcommand\Ind{\mathbbm{1}} % индикатор
\newcommand\Med{{\rm med \,}} % медиана
\newcommand\Cov{{\rm cov \,}} % ковариация
\newcommand\Mod{{\rm mod \,}} % мода
\newcommand\Pois{{\rm Pois \,}} 


\begin{document}
\tableofcontents
\newpage

\part{Теория вероятности}
\newpage

\section{Вероятностное пространство}
\qquad Методы теории вероятности работают в ситуациях, называемых стохастическими. Для них характерны три свойства:
\begin{enumerate}
	\item Непредсказуемость 
	\item Воспроизводимость 
	\item Устойчивость частот
\end{enumerate}

Для описания стохастических ситуаций ситуаций необходимо определить функцию вероятности. Её область определения назывется множеством событий.
В свою очередь событие (такое как, например, выпадание чётного числа на кубике) могут являться совокупностью неких более простых событий, описывающих стохастическую ситуацию (число, выпавшее на кубике). Последнее множество называется множетсвом элементарных исходов и обозначается $\Omega$.  

Множество событий, обозначаемое $\Ev$, должно обладать следующими интуитивными свойствами:
\begin{enumerate}
	\item Отрицание события есть событие (если <<пойдет дождь>> событие, то <<не пойдет дождь>> также событие)
	\item Объединение событий есть событие (<<пойдет дождь>> или <<пойдет снег>>)
	\item Все множество элементарных исходов является событие (<<Что-нибудь да произойдет>>)
\end{enumerate}

Формализуя эти свойства, получаем определение алгебры.
\begin{Def}
Семейство $\Ev$ подмножеств множества $\Omega$  называется \\ \underline{алгеброй}, если 
\begin{enumerate}
	\item $\forall A \in \Ev, B\in \Ev \Rightarrow A \bigcup B \in \Ev$
	\item $\forall A \in \Ev \Rightarrow \overline{A} \in \Ev$
	\item $\Omega \in \Ev$
\end{enumerate}
\end{Def}

Из аксиом алгебры и формулы $A\bigcap B = \overline{\overline{A} \bigcup \overline {B}}$ следует, что пересечений событий явялется событием.

Наименьшей возможной алгеброй является $\left\{ \Omega, \varnothing \right\}$

\begin{Def}
Семейство $\Ev$ подмножеств множества $\Omega$  называется \\ \underline{$\sigma$-алгеброй}, если 
\begin{enumerate}
	\item $\forall A_1, \dots, A_n, \ldots \in \Ev \Rightarrow \bigcup\limits_{i=1}^{\infty} A_i \in \Ev$
	\item $\forall A \in \Ev \Rightarrow \overline{A} \in \Ev$
	\item $\Omega \in \Ev$
\end{enumerate}
\end{Def}

\begin{Def}
Пусть $\mathscr{K}$ - класс подмножеств $\Omega$. $\sigma$-алгебра $\sigma (\mathscr{K})$,\\ \underline{ порожденная классом $\mathscr{K}$} --- наименьшая $\sigma$-алгебра, 
содержащая $\mathscr{K}$, то есть любая $\sigma$-алгебра, содержащая $\mathscr{K}$, содержит и $\sigma (\mathscr{K})$.
\end{Def}
\begin{Ex}
$\sigma$-алгеброй, порожденной $\mathscr{K} = A$, будет являться $\sigma(A) = \left\{ \varnothing, A, \overline(A), \Omega \right\}$.
\end{Ex}

$\sigma$-алгебра является более узким понятием, нежели алгебра, то есть любая $\sigma$-алгебра является алгеброй, а обратное, вообще говоря, неверно. \\
\begin{Ex}
Пусть $\Omega = \mathbb{R},\  \Ev$ содержит конечные подмножества $\Omega$ и их дополнения. Для такого множества выполнены все аксиомы алгебры: 
$\Omega = \overline{\varnothing} \in \Ev$, объединение конечных множеств есть конечное множество, объединение конечного множества с дополнением к конечному 
множеству так же является дополнением к некоторому множеству. То же можно сказать и об объединении двух дополнений. Таким образом, $\Ev$ является алгеброй.
Все элементы $\Ev$ либо конечны, либо континуальны, поэтому $\Ev$ не содержит $\mathbb{N}$. Но $\mathbb{N} = \bigcup\limits_{i=1}^{\infty}\{i\}$, то есть
не выполнено свойство счетной аддитивности из определения $\sigma$-алгебры.
\end{Ex}

\begin{Def}
Пара $(\Omega, \Ev)$ называется \underline{измеримым пространством}, если $\Ev$ является $\sigma$-алгеброй. Если же $\Ev$ - алгебра, то  $(\Omega, \Ev)$ --- \underline{измеримое пространство} \underline{ в широком смысле}.
\end{Def}

\begin{Def}
\underline{Вероятностью} называется функция $\Pro \colon \Ev\rightarrow \mathscr{R}_+$, удовлетворяющая свойстам
\begin{enumerate}
	\item $\forall A \in \Ev \quad \Pro (A) \ge 0$
	\item $\forall A_1, \dots, A_n, \ldots \in \Ev \quad A_i \bigcap A_j  = \varnothing\  (i \not= j)  \Rightarrow \Pro (\bigcup\limits_{i=1}^{\infty} A_i) = \sum\limits_{i = 1}^{\infty} A_i$
	\item $\Pro (\Omega) = 1$
\end{enumerate}
\end{Def}

\begin{Def}
\underline{Вероятностным пространством} $(\Omega, \Ev, \Pro)$ называется измеримое пространство $(\Omega, \Ev)$, снабженное вероятностью $\Pro$.
\end{Def}
\begin{Wtf}
Кому вообще нужна $\sigma$-алгебра событий, и зачем весь этот огород, если можно рассматривать множество всех подмножеств множества $\Omega$? Когда-то кто-то доказал, что в случае очень большого множества элементарных исходов, например, континуального, множество $2^{\Omega}$ будет иметь такую крокодильски большую мощность, что вся теория сломается. Таким образом, алгебры нужны для того, чтобы вероятность имела хорошую область определения.
\end{Wtf}

\paragraph{Свойства вероятности}
\begin{enumerate}
	\item $\Pro (\varnothing) = 0$ 
	\item $\Pro (\overline{A}) = 1 - \Pro (A)$
	\item $A \subseteq B \quad \Rightarrow \Pro (A) \le \Pro (B)$
	\item $\Pro (A) \le 1$
	\item $\Pro (A \bigcup B) = \Pro (A) + \Pro (B) - \Pro (AB)$ 
	\item $\Pro (A \bigcup B) \le \Pro (A) + \Pro (B)$ 
	\item $\Pro (\bigcup\limits_{i=1}^{n} A_i) = \sum\limits_{k=1}^{n} \sum\limits_{i_1<\dots <i_k} (-1)^{k+1} \Pro(A_{i_1}A_{i_2}\ldots A_{i_k})$
	\item $\Pro (\bigcap\limits_{i=1}^{n} A_i) \ge 1 - \sum\limits_{i=1}^{n} \Pro (\overline{A_i})$ - неравенство Бонферрони
\end{enumerate}

Второй пункт в определении вероятностной меры нельзя заменить аналогичным с конечными объединением и суммой. Однако если добавить к данному требованию так 
называемое свойство непрерывности вероятностной меры, т.е $$\forall B_1, B_2, \ldots \in \Ev \quad B_{n+1} \subseteq B_n \Rightarrow \lim_{n \to \infty} \Pro(B_n) = \Pro(B)$$, то они вместе будут эквивалентны 2. из определения вероятности.

\begin{St}
$\forall A_1, \dots, A_n, \ldots \in \Ev \quad A_i \bigcap A_j  = \varnothing\  (i \not= j)  \Rightarrow \Pro (\bigcup\limits_{i=1}^{\infty} A_i) = \sum\limits_{i = 1}^{\infty} A_i
\Leftrightarrow ( \forall A_1, \dots, A_n \in \Ev \quad A_i \bigcap A_j  = \varnothing\  (i \not= j)  \Rightarrow \Pro (\bigcup\limits_{i=1}^{n} A_i) = \sum\limits_{i = 1}^{n} A_i)  \land  (\forall B_1, B_2, \ldots \in \Ev \quad B_{n+1} \subseteq B_n \Rightarrow \lim\limits_{n \to \infty} \Pro(B_n) = \Pro(B))$
\end{St}
\begin{Proof}
\\ $\Rightarrow$\\
Обозначим $C_n = B_n \setminus B_n+1$. Множества $B, C_1, C_2, \ldots$ не имеют общих точек.\\
$\forall n \quad B_n =  \bigcup\limits_{k=n}^{\infty} C_k \bigcup B$. Тогда $\Pro(B_1) = \Pro(B) + \sum\limits_{k=1}^{\infty} \Pro(C_k)$. Отсюда следует, что ряд в правой части сходится, так как имеет конечную сумму.
$\Pro(B_n) = \Pro(B) + \sum\limits_{k=n}^{\infty} \Pro(C_k)$. При $n \to \infty$ сумма ряда стремится к нулю как остаточный член ряда из предыдущего выражения.
В предельном переходе получаем свойство непрерывности.
\\ $\Leftarrow$\\
Рассмотрим произвольный набор $A_1, A_2, \ldots \in \Ev \quad A_iA_j = \varnothing$.\\
$\Pro(\bigcup\limits_{i=1}^{\infty} A_i) = \Pro(\bigcup\limits_{i=1}^{n} A_i) + \Pro(\bigcup\limits_{i=n + 1}^{\infty} A_i) =\sum\limits_{i = 1}^{n} \Pro(A_i) +  
\Pro(\bigcup\limits_{i=n + 1}^{\infty} A_i) $.\\
 Обозначим $B_n = \bigcup\limits_{i=n + 1}^{\infty} A_i,\quad B_{n+1} \subseteq B_n \quad \forall n,\quad \bigcap\limits_{n=1}^{\infty} B_n= \varnothing$ \\
$\sum\limits_{i=1}^{\infty} \Pro(A_i) = \lim\limits_{n \to \infty} (\Pro(\bigcup\limits_{i=1}^{\infty} A_i) - \Pro(B_n)) = \Pro(\bigcup\limits_{i=1}^{\infty} A_i) - \lim\limits_{n \to \infty} \Pro(B_n) = \Pro(\bigcup\limits_{i=1}^{\infty} A_i)$
\end{Proof}

\begin{Th}[Каратеодори]
Пусть $(\Omega, \Ev)$ --- измеримое пространство в широком смысле, а некоторая функция $\Pro$ обладает свойствами вероятностной меры.Тогда на измеримом пространстве
$(\Omega, \sigma(\Ev))\  \exists !\  \Pro' \colon \forall A \in \Ev \quad \Pro(A) = \Pro'(A)$
\end{Th}
\begin{Proof}
отсутсвует
\end{Proof}\\\\
\begin{Why}
Зачем это нужно? Теорема Каратеодори говорит о том, что любую вероятностную меру, заданную на алгебре, можно однозначно продолжить на $\sigma$-алгебру,
то есть расширить область ее определения. При этом значения функции на алгебре не изменятся. Теорема будет использоваться при определении интеграла Лебега.
\end{Why}
\newpage


\section{Условная вероятность. Независимость событий}

\qquadРассмотрим произвольное $B \in \Ev \colon \quad \Pro(B) > 0$.
\begin{Def}
\underline{Условной вероятностью} события $A \in \Ev$ при условии $B$ называется $\frac{\Pro(AB)}{\Pro(B)} =\colon \Pro(A|B) = \Pro_B(A)$
\end{Def}

Что это означает на пальцах? Условная вероятность $\Pro(A|B)$ --- это веротяность того, что произойдет событие $A$, если мы точно знаем, что произошло событие $B$.\\

\parbox[b][3 cm][t]{20mm}{\includegraphics[height=30mm]{cond_prob}}
\hfill
\parbox[b][3 cm][t]{100mm}{
	Графически это означает, что, когда произошло событие $B$, мы оказались в круге $B$. Тогда формула  $\frac{\Pro(AB)}{\Pro(B)}$ есть просто вероятность попасть в $AB$.
}\\

Из определения следует так называемый <<Закон умножения вероятностей>>:
$$\Pro(A|B)\Pro(B)=\Pro(AB)$$

Легко проверяется, что $(B, \Ev_B, \Pro_B)$, где $\Ev_B = \Set{A \bigcap B}{A \in \Ev}$, так же является вероятностным пространством. \\
\begin{Wtf}
Зачем нужно требование $\Pro(B) > 0$, если можно в случае $\Pro(B) = 0$ доопределить условную вероятность нулем как вероятность при условии невозможного события?
При таком доопределении нарушится аксиома 3. вероятности $\Pro_B$, поскольку $\Pro_B(B)$ по доопределению будет равно $0$.
\end{Wtf}

\begin{Def}
События $A, B \in \Ev$ называются \underline{независимыми}, если $$\Pro(AB) = \Pro(A) \Pro(B)$$.
\end{Def}

Для независимых событий $$\Pro(A|B) = \frac{\Pro(A)\Pro(B)}{\Pro(B)} = \Pro(A)$$.\\
\begin{Ex}
Являются ли несовместные события ($AB = \varnothing$) независимыми? Нет, пусть  $A, B \in \Ev \colon \quad \Pro(A) > 0, \ \Pro(B) > 0$. Тогда $\Pro(AB) = \Pro(A)\Pro(B) = 0$, 
что является противоречием. По-простому, если произошло одно из несовместных событий, то второе уже не может произойти, и его условная веротяность равна 0, а не
вероятности самого события, что требуется для независимости.
\end{Ex}

Следующее определение обобщает понятие независимости на произвольное количество событий.
\begin{Def}
События $A_1, A_2, \dots, A_n$ называются \underline{независимыми в совокупности}, если 
$$\forall m = 2, \dots, n \quad \forall 1 \le j_1 < \ldots < j_m \le n \quad 
\Pro(\bigcap_{k=1}^{m}A_{j_k})=\prod_{k=1}^{m} \Pro(A_{j_k})$$
\end{Def}
\begin{Ex}
На примере тетраэдра Бернштейна можно убедиться в том, что попарной независимости событий недостаточно для независимости в совокупности. Рассмотри тетраэдр, у 
которого три стороны покрашены в красный, синий и зеленый, а четвертая содержит все три цвета. События \{выпадет красный\}=\{К\}, \{выпадет синий\}=\{С\}, \{выпадет зеленый\}=\{З\}
попарно независимы (например, вероятность события \{С\}$\bigcap$\{К\} равна веротяности выпадения четвертой грани, т. е. $\frac{1}{4}$, в то время как выпадения 
каждого цвета равна $\frac12$). Однако $\Pro$(\{С\}$\bigcap$ \{К\}$\bigcap$ \{З\}) = $\frac14 \not= (\frac12)^3$.
\end{Ex}
\newpage

\section{Формула полной веротяности. Формула Байеса}

\begin{Def}
$B_1, \ldots, B_n$ образуют \underline{полную группу}, если выполнены следующие условия:
	\begin{enumerate}
		\item $\Pro(B_i) > 0 \quad \forall i = 1, \ldots, n$
		\item $B_iB_j = \varnothing \quad (i \not= j)$
		\item $\bigcup\limits_{i=1}^nB_i = \Omega$
	\end{enumerate}
\end{Def}

\begin{Th}
Пусть $B_1, \ldots, B_n$ образуют полную группу. Вероятность события $A \in \Ev$ можно вычислить по \underline{формуле полной вероятности}:
$$\Pro(A) = \sum\limits_{i=1}^{n} \Pro(A|B_i)\Pro(B_i)$$
\end{Th}

\begin{Proof}
\\
$A=\bigcup\limits_{i=1}^{n}AB_i, \quad AB_i \bigcap AB_j = \varnothing \quad (i \not= j)$ \\
$\Pro(A) = \sum\limits_{i=1}^n \Pro(AB_i) = \sum\limits_{i=1}^{n} \Pro(A|B_i)\Pro(B_i)$ \\
Последний переход следует из  закона умножения вероятностей.
\end{Proof}
\\

Первое требование определения полной группы необходимо для возможности определить условную веротяность, второе позволяет 
разбить множество $A$ на непересекающиеся части. Третье требование, вообще говоря, можно ослабить, потребовав, чтобы $A \subseteq \bigcup\limits_{i=1}^nB_i$.
Доказательство при этом не изменится. \\
\begin{Ex}
Проиллюстрировать формулу полной вероятности можно обычным экзаменом: $A$ - \{студент сдал экзамен\}, $B_i$ - \{студент попал к преподавателю $i$\}.
Как и в любой другой лотерее, можно оценить вероятность попадания к преподавателю $i$, то есть $\Pro(B_i)$, а трезво оценивая свои силы можно прикинуть 
и вероятность сдать тому или иному преподавателю $\Pro(A|B_i)$. Зная все вышеперечисленое, несложно по формуле вычислить вероятность успешной сдачи.
\end{Ex}
\\

Формула полной веротяности используется для вычисления априорной вероятности, т.е. вероятности события, которое  еще не произошло.
Пусть теперь \\$\Pro(A) > 0$. Тогда $\Pro(B_i|A)=\frac{\Pro(AB_i)}{\Pro(A)}$. Используя формулу полной вероятности, получаем \underline{формулу Байеса}:
$$\Pro(B_i|A)=\frac{\Pro(A|B_i)\Pro(B_i)}{\sum\limits_{j=1}^n\Pro(A|B_j)\Pro(B_j)}$$

Формула Байеса используется для вычисления апостериорной вероятности. То есть уже известно, что произошло некоторое событие $A$, и нужно вычислить вероятность
того, что произошло некоторое $B_i$. В примере с экзаменом, например, может быть известно, что студент не сдал экзамен, и хочется вычислить вероятность того, что он
сдавал преподавателю <<Р>>.

\newpage
\section{Случайные величины}

\qquad Случайные события "--- это хорошо, но с события типа <<на монетке выпал герб>> плохо формализуемы, а мы хотим формальности и математичности. Поэтому вместо всяких событий хочется работать с числами. Вот этим и займемся. При рассмотрении случайных событий мы ввели вероятностное пространство, которе выглядит так:
$$(\Omega, \Ev, \Pro),$$
где $\Omega$ "--- множество элементарных событий, $\Ev$ "--- $\sigma$-алгебра подмножеств множества элементарных событий, а $\Pro$ "--- вероятность. Мы же будем рассамтривать теперь тройку
$$(\Real, \Bor, \Pro),$$
где $\Real$ "--- действительная прямая, $\Bor$ "--- борелевская $\sigma$-алгебра, а $\Pro$ "--- вероятность. Поясним.

\begin{Def}
\underline{Борелевской $\sigma$-алгеброй} называется минимальная $\sigma$-алгебра, содержащая все открытые подмножества топологического пространства. Элементы борелевской $\sigma$-алгебры называются \underline{борелевскими множествами}.
\end{Def}
\begin{Wtf}
Мы будем рассматривать только топологическое пространство $\Real$, так что это стремное словосочетание можно прямо 
сейчас забыть и понимать открытое множество как открытое множество из матана (все точки внутренние).
\end{Wtf}\\
\begin{Ex}
Покажем, что все <<хорошие>> множества являются Борелевскими.
\begin{enumerate}
\item Все открытые интревалы входят по определению.
\item Отрезок вида $[a, b]$ входит как $\overline{(-\infty, a) \bigcup (b, +\infty)}$.
\item Точка ходит как вырожденный отрезок $[a, a]$.
\item Счетное объединение таких множеств входит по поределению.
\end{enumerate}
\end{Ex}

Теперь формально введем понятие случайной величины (может использоваться сокращение с.в.).

\begin{Def}
Пусть $(\Omega, \Ev, \Pro)$ "--- вероятностное пространство.\\ Тогда \underline{случайной величиной $\xi$} называется функция $\xi : \Omega \to \Real$, измеримая относительно $\Ev$ и $\Bor$. По-другому, $\xi$ "--- случайная величина, если
$$\forall B \in \Bor \quad \xi^{-1}(B) = \lbrace \omega : \xi(\omega) \in B \rbrace \in \Ev$$.
\end{Def}
\begin{Wtf}
Таким финтом ушами мы, по сути, сопоставили каждому событию какое-то <<хорошее>> множество на числовой прямой, и можем рассматривать не вероятности событий, а вероятности попадания в эти <<хорошие>> подмножества числовой прямой.
\end{Wtf}

Введем еще несколько бесполезных определений, которые в дальнейшем использоваться не будут, но знать их не вредно.

\begin{Def}
С каждой случайной величиной свяжем два вероятностных пространства: первое --- $(\Omega, \Ev_\xi, \Pro)$ --- вероятностное пространство, \underline{порожденное $\xi$}. Здесь 
$\Ev_\xi$ - наименьшая $\sigma$-алгебра, для которой выполняется свойство измеримости. Второе --- $(\Real, \Bor, \Pro_\xi)$, где $\Pro_\xi(B) = \Pro(\xi^{-1}(B)) \quad \forall B \in \Bor$ и называется \underline{распределением вероятностей $\xi$}.
\end{Def}

Идем дальше в~сторону упрощения работы со случайностями. Вместо того чтобы рассматривать произвольные борелевские множества, мы будем рассамтривать только множества вида $(-\infty, x)$. Действительно, интервал $(a, b)$ получается из~полупрямых так: $(a, b) = (-\infty, b) \setminus (-\infty, a]$  Таким образом, мы можем рассматривать случайные величины только на таких множествах. Здесь имеется в виду, что для удовлетворения определению случайной величины достаточно измеримости только на
 полупрямых, что следует из следующих свойств полного прообраза: прообраз объединения есть объединение прообразов, прообраз пересечения есть пересечение прообразов,
 прообраз отрицания есть отрицание прообраза. Выше показано, что из полупрямых с помощью этих операций можно получить интервалы, а из интервалов и все $\Bor$.

Теперь несколько полезных утверждений. Пусть $\xi$ --- случайная величина. Тогда $-\xi$ также случайная величина, так как её прообраз от любой полупрямой является
прообразом $\xi$ от симметричной полупрямой, то есть лежит в $\Ev$. $\xi + c$ также будет случайной величиной, поскольку ее прообразом для любой полупрямой будет
прообраз $\xi$ для полупрямой, сдвинутой на $c$, то есть будет лежать в $\Ev$.

\begin{St}
Пусть $\xi, \eta$ --- случайные величины. Тогда множество $\Set{\omega}{\xi(\omega) < \eta(\omega)}$ является событием.
\end{St}
\begin{Proof}
$\Set{\omega}{\xi(\omega) < И\eta(\omega)} = \bigcup\limits_{r \in \mathbb{Q}}\Set{\omega}{\xi(\omega) < r, \eta(\omega) > r}$. 
Заметим, что $\Set{\omega}{\xi(\omega) < r)}$ является событием. Аналогично для $\eta$. Выражение, написанное выше, является счетным объединением пересечений двух событий, то есть событием.
\end{Proof}

Похожими махинациями, а также с использованием этого утверждения, доказывается, что $\xi^2, \xi + \eta, \xi\eta$ являются случайными величинами.
Более того, если $\xi_1, \ldots, \xi_n$ --- с.в., а функция $\phi(x_1, \ldots, x_n)$ является непрерывной на множестве их значений, то $\phi(\xi_1, \ldots, \xi_n)$ будет случайной 
величиной. Это не доказывалось.

\begin{Def}
Рассмотрим вероятностное пространство $(\Omega, \Ev, \Pro)$ и определенную на нем случайную величину $\xi$. Тогда её \underline{функцией распределения $F_\xi(x)$}
 называется функция $F_\xi : \Real \to \Real$
$$F_\xi(x) = \Pro(\omega : \xi(\omega) < x) = \Pro(\xi < x)$$.
\end{Def}

Запись $\Pro(\xi < x)$ является в некотором смысле жаргонной, так как аргументов вероятности должно быть событие из $\Ev$. Но $\xi < x$ мы в дальнейшем будем 
отождествлять с оъединением элементарных событий, образ которых меньше $x$. Из определения случайной величины получаем, что это объединение является событием,
поэтому применение к нему функции вероятности корректно.

Функция распределения (сокращение ф.р.) является очень полезной штукой, поскольку имеет достаточно простой вид и несет в себе всю информацию о распределении, то есть однозначно 
определяет $\Pro_\xi$.

Рассмотрим основные свойства функции распределения:
\begin{enumerate}
	\item $F_\xi(x) \in [0, 1]$
	\item $\lim\limits_{x \to -\infty} F_\xi(x) = 0$
	\item $\lim\limits_{x \to +\infty} F_\xi(x) = 1$
	\item $F_\xi(x)$ монотонно не убывает.
	\item $F_\xi(x)$ непрерывна слева.
\end{enumerate}

Вероятность попадания с.в. в полуинтервал $\Pro_\xi[a,b) = F_\xi(b) - F_\xi(a)$. При стремлении $b \to a$ получим $\Pro(\xi = a) = F_\xi(a+) - F_\xi(a)$, то есть 
вероятность попадания в точку равна скачку функции распределения в этой точке.

\begin{Def}
Точка $x_0$ называется \underline{точкой роста} $F_\xi(x)$, если $\forall \epsilon > 0 \quad \Pro(x_0 - \epsilon \le \xi < x_0 + \epsilon) > 0$
\end{Def}
\begin{Ex}
Это очень полезный пример, который будет использоваться в матстате и который очень любят спрашивать. Пусть $\xi$ --- случайная величина. $\eta = F_\xi(\xi)$. Чему равна
$F_\eta(x)$? По определению $F_\eta(x) = \Pro(\eta < x) = \Pro(F_\xi(\xi) < x)=\Pro(\xi < F_\xi^{-1}(x)) = F_\xi(F_\xi^{-1}(x))=x$. Вообще, тут было бы неплохо 
сказать, что $F_\xi$ непрерывна и строго монотонна, чтобы со спокойной совестью использовать обратную функцию. Таким образом $\eta$ имеет равномерное распределение.
\end{Ex}

\newpage

\section{Понятие меры и интеграла Лебега}

\qquad Мера Лебега вводится потихонечку: сначала для полуинтервала, потом для борелевских множеств, а затем и для всей числовой прямой. Основная идея --- обобщение
понятия длины на страшные, ненормальные множества.

Вспомним сначала аксиомы меры $\mu$ из функана (хех): это функция на множестве $B$ (в нашем случае $[0, 1)$), $\mu \colon B \to \Real$ со свойствами
\begin{enumerate}
	\item $\forall A \in B \quad \mu(A) \ge 0$
	\item $\forall A_1, A_2, \ldots \in B \colon A_iA_j = \varnothing \quad (i \not= j) \Rightarrow \mu(\bigcup\limits_{i=1}^\infty A_i) = \sum\limits_{i=1}^\infty \mu(A_i)$
\end{enumerate} 

Введем сначала меру на борелевских множествах полуинтервала $[0, 1)$, то есть на $\Bor_{[0, 1)}$. Итак, 
\begin{itemize}
	\item На полуинтервалах $(a, b)$ введем меру как $\mu_{[0, 1)}((a, b)) = b - a$
	\item Тогда мера одной точки равна нулю, и мы можем не обращать внимание на концы множеств
	\item Любое конечное объединение, пересечение, отрицание таких интервалов есть конечное объединение интервалов (и, возможно, конечное число точек-концов)
	На них введем меру как сумму мер этих интервалов.
	\item Теперь осталось определить меру на бесконечных объединениях/пересечениях. Для этого воспользуемся теоремой Каратеодори, согласно которой можно продолжить
	меру на $\sigma$-алгебре.
\end{itemize}

Аналогичным образом определим меру $\mu_{[k, k+1)}$ на всех полуинтервалах вида $[k, k+1) \quad (k \in \mathbb{Z})$.
Осталось доопределить меру на всей $\Bor$. $\forall A \in \Bor \quad$
 $$\mu(A)=\sum\limits_{i=-\infty}^{\infty}\mu_{[i, i+1)}(A \bigcap [i, i+1))$$
 
 Теперь введем интеграл \underline{интеграл Лебега} (интеграл по мере Лебега). В отличие от интеграла Римана, где происходит разбиение области определения и выбирается
 значение функции из образа элемента разбиения, в интеграле Лебега разбивается область значений (то есть $Oy$), и некоторое значение из элемента разбиения умножается на
 меру прообраза этого элемента, затем все благополучно складывается. Введем теперь это формально.
 
 Будем рассматривать функции $f \colon \Real \to \Real$ такие, что $\forall c \in \Real \quad \Set{x}{f(x) < c} \in \Bor$, то есть прообразы полупрямых являются
  измеримыми множествами. А как было показано выше, отсюда следует, что прообразы всех борелевских множеств являются измеримыми.
  
  Введем сначала понятие \underline{индикатора}. Индикатор события $A$ - это случайная величина, принимающая значение 1, если событие произошло, и 0 в противном случае.
  Таким образом
  \[
  	\Ind(x) = 
  	\begin{cases}
  		1, x \in A \\
  		0, x \not\in A
  	\end{cases}
  \]
  
 Определим интеграл Лебега на полуинтервале $[0, 1)$
\begin{itemize}
 	\item Пусть функция имеет вид $f(x) = \sum\limits_{i=1}^ky_i \Ind(A_i) \quad (i \not= j \Rightarrow A_iA_j = \varnothing, \ \bigcup_{i=1}^k A_i= [0,1))$. Функции такого вида 		называются \underline{финитными}.  В этом случае
 		$$\int\limits_0^1f(x)\mu(dx) = \sum\limits_{i=1}^k y_i \mu(A_i) $$
	То есть берется мера кусочка, на котором функция принимает значение $y_i$, и умножается на это значение. Получается нечто, напоминающее площадь под графиком.
	\item Пусть теперь $f(x) \ge 0$ на $[0, 1)$. Будем приближать функцию финитной. Возьмем отрезок области значений $[0, n], n \in \mathbb{N}$. Разобьем этот отрезок на
	$n2^n$ кусочков $[\frac{k-1}{2^n}, \frac{k}{2^n}], k = 1, 2, \dots, n2^n$. На каждом кусочке скажем, что значение функции равно $\frac{k-1}{2^n}$. Осталось приблизить 
	$[n, +\infty)$. Будем считать это одной частью, на которой функция принимает значение $n$. Осталось устремить n к бесконечности: тогда, так как размер каждого кусочка первой части равен $\frac{1}{2^n}$, их длина станет бесконечно малой, а та часть, которую мы <<обрубили>> сверху (то есть $[n, +\infty)$), уйдет в бесконечность. Итак,
	$$ \int\limits_0^1 f(x) \mu(dx) = \lim_{n \to \infty}  \biggl[  \sum\limits_{k=1}^{n2^n} \frac{k-1}{2^n} \mu\biggl(\Set{x}{\frac{k-1}{2^n} \le f(x) < \frac{k}{2^n}}\biggl) 
	+ n \mu(\Set{x}{f(x) \ge n})\biggl]$$
	\item Остался случай произвольной функции $f(x)$. Разобьем ее на две: одна функция совпадает с $f(x)$ там, где та положительна, и равняется 0 в остальных случаях,
	другая равна $|f(x)|$ там, где $f(x)$ отрицательна, и 0 иначе. 
	$$ f^+(x) = \max\{0, f(x)\},\quad f^-(x) = -\min\{0, f(x)\}$$
	Для каждой из этих функций интеграл определен по предыдущему пункту. Пользуясь тем, что $f(x) = f^+(x) - f^-(x)$, определим интеграл так:
	$$  \int\limits_0^1 f(x) \mu(dx) =  \int\limits_0^1 f^+(x) \mu(dx) - \int\limits_0^1 f^-(x) \mu(dx) $$
	В случае, если оба интеграла в правой части расходятся, интеграл от $f(x)$ не определен. 
	Так как $|f(x)| = f^+(x) + f^-(x)$, сходимость интеграла Лебега от модуля функции (абсолютная сходимость) эквивалента сходимости интеграла от самой функции
	(то есть обычной сходимости). Это следует из того, что интеграл сходится только в случае конечности обоих интегралов правой части (иначе он не определен), откуда 
	следует конечность их суммы и разности. Таким образом, для интеграла Лебега не существует условно сходящихся функций.
\end{itemize}

	Аналогично вводим интеграл на каждом полуинтервале $[i, i+1), \quad i \in \mathbb{Z}$. Тогда на всей прямой интеграл по множеству $A \subset \Real$ будет определяться так:
	$$ \int\limits_A f(x) \mu(dx) = \sum\limits_{i=-\infty}^{+\infty} \int\limits_{A \bigcap [i, i+1)} f(x) \mu(dx) $$
\begin{Ex}
С помощью интеграла Лебега можно считать интегралы от функций, об интегрировании которых раньше было страшно даже подумать. Например, от функции Дирихле:
  \[
  	D_{[0,1)}(x) = 
  	\begin{cases}
  		1, x \in [0,1) \setminus \mathbb{Q} \\
  		0, x \in \mathbb{Q}
  	\end{cases}
  \]
  Данная функция является финитной, а именно $D_{[0,1)}(x) = \Ind([0,1) \setminus \mathbb{Q})$. Поэтому по первому пунккту
  $$ \int\limits_0^1 D_{[0,1)}(x) \mu(dx) = 1 $$
\end{Ex}

  В дальнейшем $\mu(dx)$ будет опускаться обозначаться просто как $dx$ или $dy$ чтобы подчеркнуть, что считается именно интеграл Лебега.
  
 \newpage
\section{Виды распределений}

Распределения случайных величин можно разделить на 3 типа: непрерывные, дискретные и сингулярные.

\begin{Def}
	Случайная величина $\xi$ называется \underline{абсолютно непрерывной}, если существует интегрируемая функция $p_\xi(x) \ge 0, \ x \in \Real$ такая, что
	функцию распределения $\xi$ является почти всюду (за исключением не более, чем счетного числа точек) дифференцируемой функцией и представима в виде
	$$F_\xi(x) = \int\limits_{-\infty}^x p_\xi(y)dy$$
	Отсюда следует, что функция распределения непрерывна на $\Real$. $p_\xi(x)$ называется \underline{плотностью распределения},
	и почти всюду выполнено $p_\xi(x)=F_\xi'(x)$.
	Плотность, вообще говоря, определена не однозначно.
\end{Def}

\begin{Def}
	Случайная величина $\xi$ называется \underline{дискретной}, если множество точек роста не более, чем счетно, но распределение не является сингулярным, или, 
	другими словами $\exists B = \{x_1, x_2, \ldots\} \colon \Pro(\xi \in B) = 1$.
\end{Def}

\begin{Def}
	Случайная величина $\xi$  называется \underline{сингулярным}, если $F_\xi$ непрерына, и $\exists B \in \Bor \colon \mu(B) = 0, \ \Pro(\xi \in B) = 1$, то есть множество значений случайной величины имеет меру 0, но вероятность попасть в каждую точку этого множества так же нулевая.
\end{Def}

Пара слов о жизненном смысле определений: непрерывная случайная величина имеет областью значений континуальное множество, при это вероятность попасть в отдельно взятую точку нулевая. Пример: равномерное распределение по отрезку. Плотность же отражает вероятность попасть в ту или иную область: интеграл по области равен это вероятности. Дискретная случайная величина принимает конечное или счетное множество значений, вследствие этого имеет ступенчатую функцию распределения, например, бросок монетки имеет дискретное распределение. Сингулярное распределение --- это крокодил, который 
не встречается в жизни и будет рассмотрен отдельно.

\begin{St}
	Дискретная случайная величина имеет не более, чем счетное число скачков.
\end{St}
\begin{Proof}
Из свойств функции распределения следует, что дискретная величина имеет не больше двух скачков величины больше $\frac12$. Аналогично, скачков величины больше $\frac13$ не больше 3. То есть скачков величины больше $\frac1n$ не более n. Для любого скачка можно указать $n \in \mathbb{N}$ такое, что величина, этого скачка больше 
$\frac1n$. Значит,каждому скачку можно поставить в соответствие $n$, множество которых счетно. При этом для каждого $n$ существует не более чем счетное число скачков, ему соответсвующих (величины $>\frac1n$). А так как объединение не более, чем счетного числа не более, чем счетных множеств, не более, чем счетно, получаем 
требуемое. 
\end{Proof}\\ \\
\begin{Ex}
Для полного счастья приведем пример сингулярной случайной величины. Пусть функция распределения - так называемая лестница Кантора (см. рисунок).
\parbox[b][3 cm][t]{20mm}{\includegraphics[height=30mm]{kantor}}
\hfill
\parbox[b][3 cm][t]{100mm}{
	Посчитаем меру множества, на котором функция константа, то есть точки этого множества не будут точками роста: сначала это одна ступенька длины 1/3, потом две длины 1/9, и т.д.

}\\
	$$ \frac13 + \frac29 + \frac4{27} = \frac13 \sum\limits_{k=1}^\infty(\frac23)^{k-1} = 1$$
	Тогда множество точек роста имеет меру 0 в силу свойства аддитивности меры.
\end{Ex}
\\

Вообще говоря, существуют менее изысканные примеры сингулярных распределений. Например, при стрельбе из лука в круглую мишень распределение будет сингулярным,
если стрелок попадает только в точки одной прямой. В самом деле, двумерная мера прямой равна 0, как и вероятность попасть в каждую отдельную точку. 

\begin{Th} [Лебега]
	Любую случайную величину можно представить в виде суммы дискретной, абсолютно непрерывной и сингулярной случайной величины. То есть 
	$$ F(x) = \alpha_dF_d(x) + \alpha_cF_c(x) + \alpha_sF_s(x), \quad \alpha_d + \alpha_c + \alpha_s = 1$$
\end{Th}
\begin{Proof}
вышло и не вернулось
\end{Proof}

\newpage
\section{Характеристики случайных величин}

\underline{Математическое ожидание} (обозначается $\Expec$) обобщает понятие среднего арфиметического для произвольной случайной величины и показывает, какие значения в среднем принимает случайная величина. Оно, как и интеграл Лебега, вводится в несколько этапов. В этом определении вероятность $\Pro$ играет роль
Лебеговой меры $\mu$.

\begin{itemize}
 	\item Если $\xi(\omega) = \sum\limits_{i=1}^kx_i \Ind(A_i) \quad (i \not= j \Rightarrow A_iA_j = \varnothing, \ \bigcup_{i=1}^k = \Omega)$. 
 	$$\Expec \xi = \int\limits_{\Omega} \xi(\omega) \Pro(d\omega) \equiv \sum\limits_{i=1}^k x_i \Pro(\Set{\omega}{\xi(\omega)=x_i}) =  \sum\limits_{i=1}^k x_i \Pro(A_i)$$
	\item $\xi(\omega) \ge 0$. В этом случае аналогично интегралу Лебега
	$$ \Expec \xi = \int\limits_{\Omega} \xi d\Pro = \lim_{n \to \infty}  \biggl[  \sum\limits_{k=1}^{n2^n} \frac{k-1}{2^n} \Pro\biggl(\Set{\omega}{\frac{k-1}{2^n} \le \xi(\omega) < \frac{k}{2^n}}\biggl) 
	+ n \Pro(\Set{\omega}{\xi(\omega) \ge n})\biggl]$$
	\item Для произвольной $\xi(\omega)$ вводятся
	$$ \xi^+(\omega) = \max\{0, \xi(\omega)\},\quad \xi^-(\omega) = -\min\{0, \xi(\omega)\}$$
	$$ \Expec \xi = \Expec \xi^+ - \Expec \xi^-$$
\end{itemize}

Вспомним, что любая случайная величина $\xi$ индуцирует вероятностное пространство $(\Real, \Bor_\xi, \Pro_\xi)$. Тогда, поскольку $\Pro_\xi(dx)$ есть вероятность попасть
в $dx$, выразим ее через функцию распределения $\Pro_\xi(dx) = F_\xi(x + dx) - F_\xi(x) = dF_\xi(x)$ Тогда перепишем матожидание в более привычной форме
$$\Expec\xi = \int\limits_{\Omega} \xi(\omega) \Pro(d\omega) = \int\limits_{-\infty}^{+\infty} x \Pro_\xi(dx) = \int\limits_{-\infty}^{+\infty} x dF_\xi(x)$$

Перечислим некоторые свойства математического ожидания:
\begin{enumerate}
	\item $\Expec(\xi + a) = \Expec\xi + a \quad \forall a \in \Real$
	\item $\Expec(a\xi) = a\Expec\xi \quad \forall a \in \Real$
	\item $\Expec(\xi + \eta) = \Expec\xi + \Expec\eta$ (здесь подразумевается, что существуют два из трех математических ожидания, из чего следует существование третьего)
\end{enumerate}
\begin{Ex}
Рассмотрим дискретную случайную величину $\xi$, которая принимает значения $n$ с вероятностью $\frac{c}{n^2} \ (c = \frac{6}{\pi^2})$. По определению
$$ \Expec\xi = \sum\limits_{n=1}^{\infty} n \frac{c}{n^2} $$
Данный ряд, очевидно, расходится. Сиутацию не спасет даже рассмотрение случайной величины $\eta$, принимающей значения $\pm n$ с вероятностью $\frac{c}{2n^2}$, 
которая имеет среднее значение 0, 
поскольку $\Expec\eta = \sum\limits_{n=1}^{\infty} \frac{c}{2n} - \sum\limits_{n=1}^{\infty} \frac{c}{2n}$, что не определено, поскольку интегралы Лебега от $\eta^+$ и $\eta^-$ расходятся.\\
\end{Ex}
\begin{Ex}
Другим примером является распределение Коши с плотностью $p_\xi(x) = \frac{1}{\pi(1+x^2)}$. График этой функции симметричен относительно 0 и похож на горку, из чего
методом пристального взгляда можно сделать вывод, что средним значением должно быть 0. Однако  $
\int\limits_{-\infty}^{+\infty} x dF_\xi(x) =  \int\limits_{-\infty}^{+\infty} x p_\xi(x)dx$ расходится, поэтому математического ожидания не существует.
\end{Ex}

\begin{Def}
\underline{Моментом порядка $k$} случайной величины $\xi$ называется $\Expec\xi^k$ \\
\underline{Абсолютным моментом порядка $k$} случайной величины $\xi$ называется $\Expec|\xi|^k$ \\
\underline{Центральным моментом порядка $k$} случайной величины $\xi$ называется $\Expec(\xi - \Expec\xi)^k$ \\
\end{Def}

\begin{Def}
\underline{Квантилью} случайной величины $\xi$ порядка $q$ называется величина $l_\xi(q)$:
\[
   	l_\xi(q) \colon 
  	\begin{cases}
  		\Pro(\xi \le l_\xi(q)) \ge q \\
  		\Pro(\xi \ge l_\xi(q) \ge 1-q
  	\end{cases}
  \]
  
  В случае $q=\frac12$ квантиль называется \underline{медианой} и обозначается $\Med\xi$.
  
  Если $q=\frac14$, то $l_\xi$ называется \underline{квартилью}, если $q=\frac1{10}$, \underline{децилью}, а если $q=\frac{1}{100}$ --- \underline{перцентилью}.
\end{Def}

Жизненный смысл медианы заключается в том, что она является точкой, вероятность попасть левее которой равна пероятности попасть правее нее. Аналогично можно 
сказать про квантиль любого порядка. Квантиль определена не единственным образом: пусть $\xi$ принимает значения $\{0, 1\}$ с вероятностями $\frac12$. Тогда медианой
$\xi$ может быть любая точка из отрезка $[0,1]$.

\begin{Def}
\underline{Интерквантильный размах} --- величина $R_\xi = l_\xi(\frac34) - l_\xi(\frac14)$ --- длина отрезка, вероятность попасть в который равна $\frac12$. 
\end{Def}

С матожиданием и медианой связана задача о <<деловых людях>>. (здесь будет ссылка) 

\begin{Def}
\underline{Мода} случайной величины $\xi$ --- это наиболее вероятное значение случайной величины. Оюозначается $\Mod\xi$.
\end{Def}

При наблюдении случайной величины важно знать не только её среднее значение (матожидание), но и то, как сильно она от него отклоняется (например, измерение линейнкой в среднем дает правильный результат, однаком необходимо знать погрешность измерения). В связи с этим вводится понятие дисперсии.

\begin{Def}
Пусть для случайной величины $\xi$ существуют конечный $\Expec\xi$ и $\Expec\xi^2$.  \underline{Дисперсией} назывется величина, равная 
$$ \Disp\xi = \Expec(\xi - \Expec\xi)^2$$
\end{Def}

Эту формулу можно привести к более простому для вычисления виду:
$$\Disp\xi = \Expec(\xi^2 - 2\xi\Expec\xi + (\Expec\xi)^2) = \Expec\xi^2 - 2\Expec\xi\Expec\xi - (\Expec\xi)^2 = \Expec\xi^2 - (\Expec\xi)^2$$


Перечислим некоторые свойства дисперсии. $\xi,\eta$ - случайные величины, $c \in \Real$.

\begin{enumerate}
	\item $\Disp\xi \ge 0$ как матожидание от неотрицательной функции
	\item $\Disp c\xi = c^2 \Disp\xi$ --- следует из определения и линейности матожидания.
	\item $\Disp(\xi+c) = \Expec(\xi + c - \Expec(\xi + c))^2 = \Expec(\xi - \Expec\xi)^2 = \Disp\xi$
	\item $\Pro(\xi = c) = 1 \Leftrightarrow \Disp\xi = 0$ --- отклонение равно нулю для константы
	\item $\Disp(\xi + \eta) = \Expec(\xi+\eta)^2 - (\Expec(\xi+\eta))^2 = \Expec(\xi^2+2\xi\eta + \eta^2) - (\Expec\xi)^2- 2\Expec\xi\Expec\eta - (\Expec\eta)^2 = \Disp\xi + \Disp\eta + 2(\Expec\xi\eta - \Expec\xi\Expec\eta)$
\end{enumerate}

\begin{Def}
\underline{Ковариация} двух случайных величин --- это величина, равная
$$ \Cov(\xi,\eta) = \Expec(\xi - \Expec\xi)\Expec(\eta - \Expec\eta)$$
\end{Def}

Ковариация положительна, если случайные величины одновременно отклоняются в одну сторону и отрицательная, если в разные. Формулу ковариации так же можно упростить, раскрыв скобки в определении:
$$\Cov(\xi,\eta) = \Expec\xi\eta - \Expec\xi\Expec\eta$$

Таким образом пятое свойство дисперсии можно переписать так:
\begin{itemize}
	\item[5.] $\Disp(\xi \pm \eta) = \Disp\xi + \Disp\eta \pm 2\Cov(\xi,\eta)$
\end{itemize}

\begin{Def}
\underline{Среднеквадратическое отклонение} --- величина $\sigma = \sqrt{\Disp\xi}$.
\end{Def}



\newpage
\section{Независимость случайных величин}
\begin{Def}
	Случайные величины $\xi, \eta$ называются \underline{независимыми}, если 
	 $$ \forall B_1, B_2 \in \Bor \quad \Pro(\xi \in B_1, \eta \in B_2) = \Pro(\xi \in B_1)\Pro(\eta \in B_2) $$
\end{Def}

\begin{St}
Для независимых случайных величин $\xi, \eta$ выполнено
$$\Expec\xi\eta = \Expec\xi\Expec\eta$$
\end{St}
\begin{Proof}
проведем только для случая дискреьных случайных величин.\\
Пусть 
\[
   	\xi = 
  	\begin{cases}
  		x_1, x_2, \ldots \\
  		p_1, p_2, \ldots
  	\end{cases}
  \]
  То есть $\xi$ приминмает значение $x_i$ с вероятностью $p_i$.
  \[
   	\eta = 
  	\begin{cases}
  		y_1, y_2, \ldots \\
  		q_1, q_2, \ldots
  	\end{cases}
  \]
  $$\Expec\xi\eta=\sum\limits_{i,j} x_iy_j\Pro(\xi=x_i, \eta=y_j) = \sum\limits_{i,j} x_iy_j\Pro(\xi=x_i)\Pro(\eta=y_j) =  \sum\limits_{i} x_i\Pro(\xi=x_i)\sum\limits_j y_j\Pro(\eta=y_j) = \Expec\xi\Expec\eta$$
\end{Proof}

Для независимых случайных величин
$$\Cov(\xi,\eta) = \Expec\xi\eta - \Expec\xi\Expec\eta = 0$$

Обратное, вообще говоря, неверно: пусть мы равновероятно выбираем одну из точек $(-1, 0), (0, 1), (1, 0), (0, -1)$. Каждая координата принимает значения $-1, 0, 1$, но координаты зависимы, так как $\Pro(x=0,  y=0) = 0$ (никогда не выбираем (0,0)), а $\Pro(x=0)\Pro(y=0) = \frac12\frac12 \not=0$. Однако
$$\Expec x = \Expec y = \Expec xy = 0$$ в силу симметрии задачи. Отсюда $\Cov(x,y) = 0$.

Таким образом ковариация показывает зависимость величин, однако не дает представления, насколько они зависимы. Для это вводится понятие коэффициента корреляции ---- нормированная ковариация.

\begin{Def}
\underline{Коэффициент корреляции} --- величина, описываемая формулой
$$\rho(\xi, \eta) = \frac{\Cov(\xi, \eta)}{\sqrt{\Disp\xi\Disp\eta}}$$
\end{Def}

Коэффициент корреляции является псевдоскалярным произведением, то есть выполнены все аксиомы скалярного произведения, кроме половины четвертой. Поэтому для нее выполнено неравенство Коши-Буняковского.

Некоторые свойства коэффициента корреляции:
\begin{enumerate}
	\item $|\rho(\xi, \eta)| \le 1$ --- неравенство Коши-Буняковского
	\item $|\rho(\xi, \eta)| = 1 \Leftrightarrow \exists a, b \colon \quad \Pro(\xi = a\eta + b) = 1$ --- равенство достигается, если случайные величины линейно зависимы
	\item для независимых случайных величин $\rho(\xi, \eta) = 0$
\end{enumerate} 



\newpage
\section{Вероятностные неравенства}
\begin{Lem}
Для любой неотрицательной неубывающей функции $g(x)$ выполнено неравенство 
$$\Pro(|\xi| > x) \le \frac{\Expec g(|\xi|)}{g(x)}$$
\end{Lem}
\begin{Proof} \\
$$\Expec g(|\xi|) = \Expec g(|\xi|) \Ind(|\xi| \ge x) + \Expec g(|\xi|) \Ind(|\xi| < x) \ge \Expec g(|\xi|) \Ind(|\xi| \ge x) \ge g(x)\Ind(|\xi| \ge x) = g(x)\Pro(|\xi| > x)$$
Здесь мы воспользовались представлением $1 = \Ind(A) + \Ind(\overline{A})$, затем неотрицательностью функции и, следовательно, ее матожидания. Далее использовалась монотонность функции, и в последнем переходе тождество $\Expec \Ind(A) = 1 \Pro(A) + 0 \Pro(\overline{A}) = \Pro(A)$
\end{Proof}

Из этой леммы слкдуют два полезных неравенства.

\begin{Th} [неравенство Маркова]
Для любой случайной величины $\xi$, имееющей конечное $\Expec|\xi|$, выполнено
$$\Pro(|\xi| > \epsilon) \le \frac{\Expec|\xi|}{\epsilon}$$
\end{Th}
\begin{Proof}\\
В неравенстве леммы возьмем $g(x) = x$.
\end{Proof}

\begin{Th} [неравенство Чебышева]
Для любой случайной величины $\xi$, имееющей конечный первый и второй момент, выполнено
$$\Pro(|\xi - \Expec\xi| > \epsilon) \le \frac{\Disp\xi}{\epsilon^2}$$
\end{Th}
\begin{Proof}\\
В неравенстве леммы возьмем $g(x) = x^2$.
\end{Proof}

\newpage
\section{Испытания Бернулли}

\begin{Def}
Дискретная случайная величина $\xi$ имеет \underline{распределение Бернулли}, если
$$ \Pro(\xi = x_1) = p,\ \Pro(\xi = x_2) = q = 1 - p, \quad x_1 \not= x_2$$
\end{Def}

\begin{Def}
\underline{Схема Бернулли} --- последовательность испытаний, удовлетворяющих следующим условиям:
\begin{enumerate}
	\item Дихотомичность --- у каждого испытания два исхода, называемые <<успехом>> и <<неудачей>> или, сокращенно У/Н.
	\item Независимость --- результаты испытаний являются независимыми событиями.
	\item Однородность --- вероятности успеха в каждом испытании равны.
\end{enumerate}
\end{Def}

Из определения следует, что одно испытание имеет распределение Бернулли. Элементарным исходом в схеме Бернулли из $n$ испытаний будет являться
$$\omega = (x_1, x_2, \ldots, x_n),$$
где $x_i$ --- результат испытания $i$. Пусть в элементарном исходе $k$ успехов. Тогда
$$\Pro(\omega) = p^kq^{n-k}$$

Покажем, что веорятность, введенная таким образом, удовлетворяет всем аксиомам вероятностной меры. Неочевидной здесь является только проверка нормировки, то есть надо доказать, что
$$ \sum\limits_{\omega}\Pro(\omega) = 1$$
Для этого просуммируем все исходы по числу успехов (обозначим $\mu_n$).
$$ \sum\limits_{\omega}\Pro(\omega) = \sum\limits_{k = 0}^n\sum\limits_{\omega\colon\mu_n=k}\Pro(\omega) = \sum\limits_{k = 0}^n\sum\limits_{\omega\colon\mu_n=k}p^kq^{n-k} = 
\sum\limits_{k = 0}^nC_n^kp^kq^{n-k} = (p+q)^n = 1$$

Рассмотрим теперь некоторые важные распределения, связанные со схемой Бернулли.

Уже рассмотренная величина $\mu_n$, равная числу успехов в $n$ испытаниях Бернулли, является случайной величиной с распределением
$$\forall k \in \Int_+ \quad \Pro(\mu_n=k) = C_n^kp^kq^{n-k}$$
Это следует из того, что исходов с $k$ успехами ровно $C_n^k$, а вероятность каждого равна $p^kq^{n-k}$.
Такое распределение называется \underline{биномиальным} и обозначается $B(n,p)$.

Рассимотрим случайные величины $X_i = \Ind(A_i)б \quad i = 1, \ldots, n$, где $A_i$ --- успех в $i$-м испытании. Каждая такая величина имеет распределение Бернулли.
Тогда число успехов можно представить так:
$$\mu_n = \sum\limits_{i=1}^nX_i$$

Найдем матожидание и дисперсию $\mu_n$.
$$\Expec\mu_n = \Expec\sum\limits_{i=1}^nX_i = \sum\limits_{i=1}^n\Expec X_i = \sum\limits_{i=1}^n(1p + 0 q) = np$$
$$\Expec X_i^2 = 1p+0q = p$$
$$\Disp X_i = \Expec X_i^2 - (\Expec X_i)^2 = p - p^2 = pq$$
В силу независимости испытаний дисперсия линейна относительно сложения
$$\Disp \mu_n = \Disp\sum\limits_{i=1}^n  X_i  =\sum\limits_{i=1}^n  \Disp X_i = \sum\limits_{i=1}^n pq = npq$$

\begin{Th} [Бернулли]
Для случайной величины с распределением $B(n,p)$
$$\Pro(|\frac{\mu_n}{n} - p| \ge \epsilon) \le \frac{npq}{n^2\epsilon^2}$$
\end{Th}
\begin{Proof} \\
Домножим обе части неравенства на $n$ и воспользуемся неравенством Чебышева:
$$\Pro(|\mu_n - pn| \ge n\epsilon) \le \frac{\Disp(\mu_n)}{(n\epsilon)^2} = \frac{npq}{n^2\epsilon^2}$$
\end{Proof}

Пусть $f(x) \in C[0, 1]$.
\begin{Def}
\underline{Многочленом Бернштейна} называется функция 
$$ B_n(x, f) = \Sum{k}{0}{n}C_n^kx^k(1-x)^{n-k}f(\frac{k}{n}), \quad x \in [0, 1]$$
\end{Def}
Заметим, что $B_n(x, f) = \Expec f(\frac{\mu_n}n),\quad  \mu_n \sim B(n, x)$. (запись $\xi \sim$ *destrname*  означает, что случайная величина $\xi$ имеет распределение *destrname*).

\begin{St}
$$B_n(x, f) \rightrightarrows f(x), \quad x \in [0,1]$$
\end{St}
\begin{Proof} \\
Пользуясь тем, что $\sum\limits_{k = 0}^nC_n^kx^k(1-x)^{n-k} = 1$ получим
$$|B_n(x, f) - f(x)| = |\sum\limits_{k = 0}^nC_n^kx^k(1-x)^{n-k}f(\frac{k}n) - \sum\limits_{k = 0}^nC_n^kx^k(1-x)^{n-k}f(x)| \le 
\sum\limits_{k = 0}^nC_n^kx^k(1-x)^{n-k}|f(\frac{k}n) - f(x)|$$
Разобьем данную сумму на две:
$$\Sum{k}{0}{n} = \sum\limits_{|\frac{k}n - x| < \delta} + \sum\limits_{|\frac{k}n - x| \ge \delta}$$
Выберем $\delta$ так, чтобы первая сумма была меньше $\frac{\epsilon}2$. Это всегда можно сделать, так как функция $f(x)$ непрерывна, а 
$\sum\limits_{|\frac{k}n - x| < \delta}C_n^kx^k(1-x)^{n-k} \le 1$.
Во второй сумме ограничим модуль числом $M = 2\sup\limits_{[0,1]} f(x)$ (1-я теорема Вейерштрасса), а к оставшейся сумме применим неравенство Чебышева, поскольку она равна вероятности 
$\Pro(|\mu_n - nx| \ge n\delta)$. 
$$\sum\limits_{|\frac{k}n - x| \ge \delta}\ldots \le 2M\sum\limits_{|\frac{k}n - x| \ge \delta}C_n^kx^k(1-x)^{n-k} \le 2M\frac1{n\delta^2}$$
Выбором $n$ сделаем вторую сумму меньше $\frac{\epsilon}2$, доказав, тем самым, равномерную сходимость.
\end{Proof}

Пусть в схеме Бернулли с вероятностью успеха $0 < p \le 1$ величина $\eta$ равна номеру первого успеха. $\eta$ является случайной величиной, принимающей натуральные значения. Найдем распределение $\eta$: серия, в которой первый успех появляется в $k$-м испытании выглядит так: НН...НУ. Отсюда
$$\forall k \in \Nat \quad \Pro(\eta = k) = (1-p)^{k-1}p = q^{k-1}p $$
Так как $\Omega = \Set{\omega_k = \underbrace{0\ldots0}_k1}{k \in \Nat}$, то 
$$\Sum{k}{1}{n}\Pro(\omega_k) = \Sum{k}{1}{n} p(1-p)^{k-1} = 1$$
Такое распределение называется \underline{геометрическим с параметром $p$}.

Пусть $\xi$ имеет геометрическое распределение с параметром $p$. Тогда
$$\Expec\xi = \Sum{k}{1}{\infty}kp(1-p)^{k-1} = -p\Sum{k}{1}{\infty}\frac{d}{dp}(1-p)^k = -p \frac{d}{dp}(\frac{1-p}{p}) = \frac1{p}$$
Аналогично, дифференцирую степенные ряды, получим диспресию
$$\Disp\xi = \frac{q}{p^2}$$

Пусть теперь $\theta$ --- число неудач до $r$-го успеха. Тогда
$$\forall k \in\Int_0 \quad \Pro(\theta = k) = p^rq^kC_{k+r-1}^{k}$$
Это следует из того, что всего испытаний было $r+k$, на последнем месте успех, а до него как-то располагаются $k$ неудач и $r-1$ успех.
Такое распределение называется \underline{отрицательным биномиальным} с параметрами $r, p$.

\newpage
\section{Предельные теоремы}

\begin{Th} [Пуассон]
Пусть $\lambda = np$. Тогда при малых $p$ и больших $n$ можно использовать приближение
$$\Pro(\mu_n = k) = C_n^kp^kq^{n-k} \approx \frac{e^{-\lambda}\lambda^k}{k!}$$
\end{Th}
\begin{Proof}
Докажем индукцией по $k$. При $k = 0$
$$\Pro(\mu_n = 0) = (1-p)^n = (1 - \frac{\lambda}{n})^n \longrightarrow e^{-\lambda} \quad (n \to \infty)$$
$$\frac{\Pro(\mu_n = k)}{\Pro(\mu_n = k-1)} = \frac{n!}{k!(n-k)!}p^kq^{n-k} \frac{(k-1)!(n-k+1)!}{n!} \frac{1}{p^{k-1}q^{n-k+1}} = \frac{(n-k+1)p}{kq}$$
$$\Pro(\mu_n = k) = \frac{(n-k+1)p}{kq}\Pro(\mu_n = k-1) = \frac{(n-k+1)\frac{\lambda}n}{k(1-\frac{\lambda}n)}\Pro(\mu_n = k-1)$$

Воспользуемся предположением индукции для $k-1$.
$$\Pro(\mu_n = k) \to \frac{(n-k+1)\frac{\lambda}n}{k(1-\frac{\lambda}n)} \frac{e^{-\lambda}\lambda^{k-1}}{(k-1)!} \longrightarrow \frac{e^{-\lambda}\lambda^{k}}{k!} (n \to \infty)$$
\end{Proof}

Следующая оценка формализует <<малость>> $p$ и <<величину>> $n$:
$$\sup\limits_k |\Pro(\mu_n = k) - \frac{e^{-\lambda}\lambda^k}{k!}| \le 2np^2$$
Таким образом, зная $n, p$ всегда можно оценить сверху погрешность аппроксимации.\\
\begin{Why}
При очень большом числе испытаний ни один нормальный компьютер не способен вычислить  $ C_n^kp^kq^{n-k}$, а уж тем более сложить их. Данная теорема позволяет сводить вычисление таких сложных вещей к вычислению экспонент.
\end{Why}

Распределение величины $\xi$ такое, что $\forall k \in \Int_+\quad  \Pro(\xi = k) =\frac{e^{-\lambda}\lambda^k}{k!}$, называется \underline{распределением Пуассона} 
и обозначается $\Pois(\lambda)$

Одно из приложений распределения Пуассона --- это пуассоновские потоки. Пусть во времени происходят некоторые события, которые мы фиксируем. $\lambda$ --- интенсивность потока --- показывает среднее число событий за единицу времени. Тогда число произошедших событий на отрезке $[0, t]$ равно $\xi_t\colon \Pro(\xi_t = k) = \frac{e^{-\lambda t}(\lambda t)^k}{k!}$.

Свойства пуассоновского распределения. ($\xi \sim \Pois(\lambda)$)
\begin{enumerate}
	\item $\Expec\xi = \lambda$
	\item $\Disp\xi = \lambda$
	\item $\xi_i \sim \Pois(\lambda_i) \quad i = 1, \ldots, n \Rightarrow \Sum{i}{1}{n}\xi_i \sim \Pois(\Sum{i}{1}{n}\lambda_i)$
\end{enumerate}

\begin{St}
Пусть независимые случайные величины $\xi_i \sim \Pois(\lambda_i), \quad i = 1, 2$. Тогда условное распределение $\xi_1$ при условии $\xi_1 + \xi_2 = n$ имеет биномиальное распределение с параметрами $n, \frac{\lambda_1}{\lambda_1 + \lambda_2}$, то есть
$$\Pro(\xi_1 = k | \xi_1 + \xi_2 = n) = C_n^kp^k(1-p)^{n-k}, \quad p = \frac{\lambda_1}{\lambda_1 + \lambda_2}$$
\end{St}
\begin{Proof}
$$\Pro(\xi_1 = k | \xi_1 + \xi_2 = n) = \frac{\Pro(\xi_1 = k, \xi_1 + \xi_2 = n}{\Pro(\xi_1 + \xi+2 = n)} = \frac{\Pro(\xi_1 = k, \xi_2 = n - k}{\Pro(\xi_1 + \xi+2 = n)}=$$
В числителе воспользуемся независимостью $\xi_1, \xi_2$, а в знаменателе свойством 3 пуассоновского распределения:
$$=\frac{e^{-\lambda_1}\frac{\lambda_1^k}{k!}e^{-\lambda_2}\frac{\lambda_2^{n-k}}{(n-k)!}}{e^{-(\lambda_1+\lambda_2)}\frac{(\lambda_1+\lambda_2)^n}{n!}} = 
C_n^k(\frac{\lambda_1}{\lambda_1 + \lambda_2})^k(\frac{\lambda_2}{\lambda_1 + \lambda_2})^{n-k}$$
\end{Proof}

\begin{Th} [Муавра-Лапласа]
Пусть $\sqrt{npq}$ велико. Тогда
$$\Pro(\mu_n = k) = \Pro(\frac{\mu_n - np}{\sqrt{npq}} = \frac{k - np}{\sqrt{npq}}) = \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}2} + o(1), \quad x \equiv \frac{k - np}{\sqrt{npq}}$$
\end{Th}
\begin{Proof} не было и не должно быть.
\end{Proof}

Рассмотрим функции
$$\phi(x) = \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}2}$$
$$\Phi(x) = \int\limits_{-\infty}^x \frac{1}{\sqrt{2\pi}}e^{-\frac{u^2}2} du = \int\limits_{-\infty}^{x}\phi(u)du$$

Заметим, что 
$$\int\limits_{-\infty}^{+\infty} \phi(u)du = 1$$ 
Это верно, так как данный интеграл сводится заменой $t = \frac{x}{\sqrt{2}}$ к известному интегралу Пуассона.

Так как $\phi(x)$ неотрицательна, и интеграл от нее по всей прямой равен 1, она является плотностью некоторого абсолютно непрерывного распределения, которое называется \underline{стандартным нормальным распределением} и обозначается $N(0, 1)$.

Пусть $\xi \sim N(0,1)$.
$$\Expec\xi^k = \int\limits_{-\infty}^{+\infty}x^k\phi(x)dx$$
$$e^{h\xi}=1 + h\xi + \frac{(h\xi)^2}{2!} + \ldots$$
$$\Expec e^{h\xi} = 1 + h\Expec\xi + \frac{h^2}{2!}\Expec\xi^2 + \ldots \equiv \psi(h)$$
Функция $\psi(h)$ называется \underline{производящей функцией моментов}.
$$\psi(h) = \int\limits_{-\infty}^{+\infty}e^{hx}\phi(x)dx = \int\limits_{-\infty}^{+\infty}\frac{1}{\sqrt{2\pi}}e^{hx-\frac{x^2}2}dx = \frac{e^{\frac{h^2}2}}{\sqrt{2\pi}}\int\limits_{-\infty}^{+\infty}e^{-\frac{(x-h)^2}2}dx = e^{\frac{h^2}2}$$
$$e^{\frac{h^2}2} = 1 + \frac{h^2}2 + \frac1{2!}(\frac{h^2}2)^2 + \ldots$$
Приравнивая это равенство к предыдущему разложению получим, что все нечетные центральные моменты равны 0.
$$\Expec\xi^{2n-1} = 0$$
$$\frac{1}{n!2^n} = \frac{\Expec\xi^{2n}} \Rightarrow \Expec\xi^{2n} = \frac{(2n)!}{n!2^n} = \frac{2n(2n-1)\ldots n \ldots 1}{n!2^n} = (2n-1)!!$$

Последняя формула позволяет очень быстро получить нужный момент, не считая интеграл по честям много раз.

\begin{Th}[Интегральная теорема Муавра-Лапласа]
Пусть $\sqrt{npq}$ велико. Тогда
$$\Pro(m_1 \le \nu_n \le m_2) = \Pro(\frac{m_1 - np}{\sqrt{npq}} \le \frac{\mu_n - np}{\sqrt{npq}} \le \frac{m_2 - np}{\sqrt{npq}}) \approx \int\limits_{x_1}^{x_2}\phi(x)dx, \quad x1 \equiv \frac{m_1 - np}{\sqrt{npq}}, x2 \equiv\frac{m_2 - np}{\sqrt{npq}}$$
\end{Th}
\end{document}