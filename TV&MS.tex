\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{bbm} % для индикатора
\usepackage{chngcntr} % без этого пакета у меня не робит counterwithin

\graphicspath{{pictures/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}

\textheight=24cm
\textwidth=16cm
\oddsidemargin=0pt
\topmargin=-1.5cm
\parindent=24pt
\parskip=0pt
\tolerance=2000
\flushbottom

\newtheorem{Th}{Теорема}
\newtheorem{Def}{Определение}
\newtheorem{Lem}{Лемма}
\newtheorem{St}{Утверждение}

\newenvironment{Proof}{\par\noindent{\bf Доказательство}}{$\blacksquare$} 
\newenvironment{Ex}{{\bf Пример}\ }{}
\newenvironment{Wtf}{\includegraphics[height=5mm]{ping}}{}
\newenvironment{Why}{\includegraphics[height= 5mm]{cat}}{}

\numberwithin{Th}{section}
\numberwithin{Def}{section}
\numberwithin{Lem}{section}
\numberwithin{St}{section}
\numberwithin{equation}{section}
\counterwithin*{section}{part}

\newcommand\Set[2]{\left\{ #1 \colon #2 \right\}}
\newcommand\Pro{\mathbb{P}} % вероятность
\newcommand\Ev{\mathscr{A}} % алгебра событий
\newcommand\Bor{\mathscr{B}} % борелевская сигма-алгебра
\newcommand\Real{\mathbb{R}} % вещественная прямая
\newcommand\Expec{\mathbb{E}} % матожидание 
\newcommand\Disp{\mathbb{D}}  % дисперсия
\newcommand\Ind{\mathbbm{1}} %индикатор


\begin{document}
\tableofcontents
\newpage

\part{Теория вероятности}
\newpage

\section{Вероятностное пространство}
\qquad Методы теории вероятности работают в ситуациях, называемых стохастическими. Для них характерны три свойства:
\begin{enumerate}
	\item Непредсказуемость 
	\item Воспроизводимость 
	\item Устойчивость частот
\end{enumerate}

Для описания стохастических ситуаций ситуаций необходимо определить функцию вероятности. Её область определения назывется множеством событий.
В свою очередь событие (такое как, например, выпадание чётного числа на кубике) могут являться совокупностью неких более простых событий, описывающих стохастическую ситуацию (число, выпавшее на кубике). Последнее множество называется множетсвом элементарных исходов и обозначается $\Omega$.  

Множество событий, обозначаемое $\Ev$, должно обладать следующими интуитивными свойствами:
\begin{enumerate}
	\item Отрицание события есть событие (если <<пойдет дождь>> событие, то <<не пойдет дождь>> также событие)
	\item Объединение событий есть событие (<<пойдет дождь>> или <<пойдет снег>>)
	\item Все множество элементарных исходов является событие (<<Что-нибудь да произойдет>>)
\end{enumerate}

Формализуя эти свойства, получаем определение алгебры.
\begin{Def}
Семейство $\Ev$ подмножеств множества $\Omega$  называется \\ \underline{алгеброй}, если 
\begin{enumerate}
	\item $\forall A \in \Ev, B\in \Ev \Rightarrow A \bigcup B \in \Ev$
	\item $\forall A \in \Ev \Rightarrow \overline{A} \in \Ev$
	\item $\Omega \in \Ev$
\end{enumerate}
\end{Def}

Из аксиом алгебры и формулы $A\bigcap B = \overline{\overline{A} \bigcup \overline {B}}$ следует, что пересечений событий явялется событием.

Наименьшей возможной алгеброй является $\left\{ \Omega, \varnothing \right\}$

\begin{Def}
Семейство $\Ev$ подмножеств множества $\Omega$  называется \\ \underline{$\sigma$-алгеброй}, если 
\begin{enumerate}
	\item $\forall A_1, \dots, A_n, \ldots \in \Ev \Rightarrow \bigcup\limits_{i=1}^{\infty} A_i \in \Ev$
	\item $\forall A \in \Ev \Rightarrow \overline{A} \in \Ev$
	\item $\Omega \in \Ev$
\end{enumerate}
\end{Def}

\begin{Def}
Пусть $\mathscr{K}$ - класс подмножеств $\Omega$. $\sigma$-алгебра $\sigma (\mathscr{K})$,\\ \underline{ порожденная классом $\mathscr{K}$} --- наименьшая $\sigma$-алгебра, 
содержащая $\mathscr{K}$, то есть любая $\sigma$-алгебра, содержащая $\mathscr{K}$, содержит и $\sigma (\mathscr{K})$.
\end{Def}
\begin{Ex}
$\sigma$-алгеброй, порожденной $\mathscr{K} = A$, будет являться $\sigma(A) = \left\{ \varnothing, A, \overline(A), \Omega \right\}$.
\end{Ex}

$\sigma$-алгебра является более узким понятием, нежели алгебра, то есть любая $\sigma$-алгебра является алгеброй, а обратное, вообще говоря, неверно. \\
\begin{Ex}
Пусть $\Omega = \mathbb{R},\  \Ev$ содержит конечные подмножества $\Omega$ и их дополнения. Для такого множества выполнены все аксиомы алгебры: 
$\Omega = \overline{\varnothing} \in \Ev$, объединение конечных множеств есть конечное множество, объединение конечного множества с дополнением к конечному 
множеству так же является дополнением к некоторому множеству. То же можно сказать и об объединении двух дополнений. Таким образом, $\Ev$ является алгеброй.
Все элементы $\Ev$ либо конечны, либо континуальны, поэтому $\Ev$ не содержит $\mathbb{N}$. Но $\mathbb{N} = \bigcup\limits_{i=1}^{\infty}\{i\}$, то есть
не выполнено свойство счетной аддитивности из определения $\sigma$-алгебры.
\end{Ex}

\begin{Def}
Пара $(\Omega, \Ev)$ называется \underline{измеримым пространством}, если $\Ev$ является $\sigma$-алгеброй. Если же $\Ev$ - алгебра, то  $(\Omega, \Ev)$ --- \underline{измеримое пространство} \underline{ в широком смысле}.
\end{Def}

\begin{Def}
\underline{Вероятностью} называется функция $\Pro \colon \Ev\rightarrow \mathscr{R}_+$, удовлетворяющая свойстам
\begin{enumerate}
	\item $\forall A \in \Ev \quad \Pro (A) \ge 0$
	\item $\forall A_1, \dots, A_n, \ldots \in \Ev \quad A_i \bigcap A_j  = \varnothing\  (i \not= j)  \Rightarrow \Pro (\bigcup\limits_{i=1}^{\infty} A_i) = \sum\limits_{i = 1}^{\infty} A_i$
	\item $\Pro (\Omega) = 1$
\end{enumerate}
\end{Def}

\begin{Def}
\underline{Вероятностным пространством} $(\Omega, \Ev, \Pro)$ называется измеримое пространство $(\Omega, \Ev)$, снабженное вероятностью $\Pro$.
\end{Def}
\begin{Wtf}
Кому вообще нужна $\sigma$-алгебра событий, и зачем весь этот огород, если можно рассматривать множество всех подмножеств множества $\Omega$? Когда-то кто-то доказал, что в случае очень большого множества элементарных исходов, например, континуального, множество $2^{\Omega}$ будет иметь такую крокодильски большую мощность, что вся теория сломается. Таким образом, алгебры нужны для того, чтобы вероятность имела хорошую область определения.
\end{Wtf}

\paragraph{Свойства вероятности}
\begin{enumerate}
	\item $\Pro (\varnothing) = 0$ 
	\item $\Pro (\overline{A}) = 1 - \Pro (A)$
	\item $A \subseteq B \quad \Rightarrow \Pro (A) \le \Pro (B)$
	\item $\Pro (A) \le 1$
	\item $\Pro (A \bigcup B) = \Pro (A) + \Pro (B) - \Pro (AB)$ 
	\item $\Pro (A \bigcup B) \le \Pro (A) + \Pro (B)$ 
	\item $\Pro (\bigcup\limits_{i=1}^{n} A_i) = \sum\limits_{k=1}^{n} \sum\limits_{i_1<\dots <i_k} (-1)^{k+1} \Pro(A_{i_1}A_{i_2}\ldots A_{i_k})$
	\item $\Pro (\bigcap\limits_{i=1}^{n} A_i) \ge 1 - \sum\limits_{i=1}^{n} \Pro (\overline{A_i})$ - неравенство Бонферрони
\end{enumerate}

Второй пункт в определении вероятностной меры нельзя заменить аналогичным с конечными объединением и суммой. Однако если добавить к данному требованию так 
называемое свойство непрерывности вероятностной меры, т.е $$\forall B_1, B_2, \ldots \in \Ev \quad B_{n+1} \subseteq B_n \Rightarrow \lim_{n \to \infty} \Pro(B_n) = \Pro(B)$$, то они вместе будут эквивалентны 2. из определения вероятности.

\begin{St}
$\forall A_1, \dots, A_n, \ldots \in \Ev \quad A_i \bigcap A_j  = \varnothing\  (i \not= j)  \Rightarrow \Pro (\bigcup\limits_{i=1}^{\infty} A_i) = \sum\limits_{i = 1}^{\infty} A_i
\Leftrightarrow ( \forall A_1, \dots, A_n \in \Ev \quad A_i \bigcap A_j  = \varnothing\  (i \not= j)  \Rightarrow \Pro (\bigcup\limits_{i=1}^{n} A_i) = \sum\limits_{i = 1}^{n} A_i)  \land  (\forall B_1, B_2, \ldots \in \Ev \quad B_{n+1} \subseteq B_n \Rightarrow \lim\limits_{n \to \infty} \Pro(B_n) = \Pro(B))$
\end{St}
\begin{Proof}
\\ $\Rightarrow$\\
Обозначим $C_n = B_n \setminus B_n+1$. Множества $B, C_1, C_2, \ldots$ не имеют общих точек.\\
$\forall n \quad B_n =  \bigcup\limits_{k=n}^{\infty} C_k \bigcup B$. Тогда $\Pro(B_1) = \Pro(B) + \sum\limits_{k=1}^{\infty} \Pro(C_k)$. Отсюда следует, что ряд в правой части сходится, так как имеет конечную сумму.
$\Pro(B_n) = \Pro(B) + \sum\limits_{k=n}^{\infty} \Pro(C_k)$. При $n \to \infty$ сумма ряда стремится к нулю как остаточный член ряда из предыдущего выражения.
В предельном переходе получаем свойство непрерывности.
\\ $\Leftarrow$\\
Рассмотрим произвольный набор $A_1, A_2, \ldots \in \Ev \quad A_iA_j = \varnothing$.\\
$\Pro(\bigcup\limits_{i=1}^{\infty} A_i) = \Pro(\bigcup\limits_{i=1}^{n} A_i) + \Pro(\bigcup\limits_{i=n + 1}^{\infty} A_i) =\sum\limits_{i = 1}^{n} \Pro(A_i) +  
\Pro(\bigcup\limits_{i=n + 1}^{\infty} A_i) $.\\
 Обозначим $B_n = \bigcup\limits_{i=n + 1}^{\infty} A_i,\quad B_{n+1} \subseteq B_n \quad \forall n,\quad \bigcap\limits_{n=1}^{\infty} B_n= \varnothing$ \\
$\sum\limits_{i=1}^{\infty} \Pro(A_i) = \lim\limits_{n \to \infty} (\Pro(\bigcup\limits_{i=1}^{\infty} A_i) - \Pro(B_n)) = \Pro(\bigcup\limits_{i=1}^{\infty} A_i) - \lim\limits_{n \to \infty} \Pro(B_n) = \Pro(\bigcup\limits_{i=1}^{\infty} A_i)$
\end{Proof}

\begin{Th}[Каратеодори]
Пусть $(\Omega, \Ev)$ --- измеримое пространство в широком смысле, а некоторая функция $\Pro$ обладает свойствами вероятностной меры.Тогда на измеримом пространстве
$(\Omega, \sigma(\Ev))\  \exists !\  \Pro' \colon \forall A \in \Ev \quad \Pro(A) = \Pro'(A)$
\end{Th}
\begin{Proof}
отсутсвует
\end{Proof}\\\\
\begin{Why}
Зачем это нужно? Теорема Каратеодори говорит о том, что любую вероятностную меру, заданную на алгебре, можно однозначно продолжить на $\sigma$-алгебру,
то есть расширить область ее определения. При этом значения функции на алгебре не изменятся. Теорема будет использоваться при определении интеграла Лебега.
\end{Why}
\newpage


\section{Условная вероятность. Независимость событий}

\qquadРассмотрим произвольное $B \in \Ev \colon \quad \Pro(B) > 0$.
\begin{Def}
\underline{Условной вероятностью} события $A \in \Ev$ при условии $B$ называется $\frac{\Pro(AB)}{\Pro(B)} =\colon \Pro(A|B) = \Pro_B(A)$
\end{Def}

Что это означает на пальцах? Условная вероятность $\Pro(A|B)$ --- это веротяность того, что произойдет событие $A$, если мы точно знаем, что произошло событие $B$.\\

\parbox[b][3 cm][t]{20mm}{\includegraphics[height=30mm]{cond_prob}}
\hfill
\parbox[b][3 cm][t]{100mm}{
	Графически это означает, что, когда произошло событие $B$, мы оказались в круге $B$. Тогда формула  $\frac{\Pro(AB)}{\Pro(B)}$ есть просто вероятность попасть в $AB$.
}\\

Из определения следует так называемый <<Закон умножения вероятностей>>:
$$\Pro(A|B)\Pro(B)=\Pro(AB)$$

Легко проверяется, что $(B, \Ev_B, \Pro_B)$, где $\Ev_B = \Set{A \bigcap B}{A \in \Ev}$, так же является вероятностным пространством. \\
\begin{Wtf}
Зачем нужно требование $\Pro(B) > 0$, если можно в случае $\Pro(B) = 0$ доопределить условную вероятность нулем как вероятность при условии невозможного события?
При таком доопределении нарушится аксиома 3. вероятности $\Pro_B$, поскольку $\Pro_B(B)$ по доопределению будет равно $0$.
\end{Wtf}

\begin{Def}
События $A, B \in \Ev$ называются \underline{независимыми}, если $$\Pro(AB) = \Pro(A) \Pro(B)$$.
\end{Def}

Для независимых событий $$\Pro(A|B) = \frac{\Pro(A)\Pro(B)}{\Pro(B)} = \Pro(A)$$.\\
\begin{Ex}
Являются ли несовместные события ($AB = \varnothing$) независимыми? Нет, пусть  $A, B \in \Ev \colon \quad \Pro(A) > 0, \ \Pro(B) > 0$. Тогда $\Pro(AB) = \Pro(A)\Pro(B) = 0$, 
что является противоречием. По-простому, если произошло одно из несовместных событий, то второе уже не может произойти, и его условная веротяность равна 0, а не
вероятности самого события, что требуется для независимости.
\end{Ex}

Следующее определение обобщает понятие независимости на произвольное количество событий.
\begin{Def}
События $A_1, A_2, \dots, A_n$ называются \underline{независимыми в совокупности}, если 
$$\forall m = 2, \dots, n \quad \forall 1 \le j_1 < \ldots < j_m \le n \quad 
\Pro(\bigcap_{k=1}^{m}A_{j_k})=\prod_{k=1}^{m} \Pro(A_{j_k})$$
\end{Def}
\begin{Ex}
На примере тетраэдра Бернштейна можно убедиться в том, что попарной независимости событий недостаточно для независимости в совокупности. Рассмотри тетраэдр, у 
которого три стороны покрашены в красный, синий и зеленый, а четвертая содержит все три цвета. События \{выпадет красный\}=\{К\}, \{выпадет синий\}=\{С\}, \{выпадет зеленый\}=\{З\}
попарно независимы (например, вероятность события \{С\}$\bigcap$\{К\} равна веротяности выпадения четвертой грани, т. е. $\frac{1}{4}$, в то время как выпадения 
каждого цвета равна $\frac12$). Однако $\Pro$(\{С\}$\bigcap$ \{К\}$\bigcap$ \{З\}) = $\frac14 \not= (\frac12)^3$.
\end{Ex}
\newpage

\section{Формула полной веротяности. Формула Байеса}

\begin{Def}
$B_1, \ldots, B_n$ образуют \underline{полную группу}, если выполнены следующие условия:
	\begin{enumerate}
		\item $\Pro(B_i) > 0 \quad \forall i = 1, \ldots, n$
		\item $B_iB_j = \varnothing \quad (i \not= j)$
		\item $\bigcup\limits_{i=1}^nB_i = \Omega$
	\end{enumerate}
\end{Def}

\begin{Th}
Пусть $B_1, \ldots, B_n$ образуют полную группу. Вероятность события $A \in \Ev$ можно вычислить по \underline{формуле полной вероятности}:
$$\Pro(A) = \sum\limits_{i=1}^{n} \Pro(A|B_i)\Pro(B_i)$$
\end{Th}

\begin{Proof}
\\
$A=\bigcup\limits_{i=1}^{n}AB_i, \quad AB_i \bigcap AB_j = \varnothing \quad (i \not= j)$ \\
$\Pro(A) = \sum\limits_{i=1}^n \Pro(AB_i) = \sum\limits_{i=1}^{n} \Pro(A|B_i)\Pro(B_i)$ \\
Последний переход следует из  закона умножения вероятностей.
\end{Proof}
\\

Первое требование определения полной группы необходимо для возможности определить условную веротяность, второе позволяет 
разбить множество $A$ на непересекающиеся части. Третье требование, вообще говоря, можно ослабить, потребовав, чтобы $A \subseteq \bigcup\limits_{i=1}^nB_i$.
Доказательство при этом не изменится. \\
\begin{Ex}
Проиллюстрировать формулу полной вероятности можно обычным экзаменом: $A$ - \{студент сдал экзамен\}, $B_i$ - \{студент попал к преподавателю $i$\}.
Как и в любой другой лотерее, можно оценить вероятность попадания к преподавателю $i$, то есть $\Pro(B_i)$, а трезво оценивая свои силы можно прикинуть 
и вероятность сдать тому или иному преподавателю $\Pro(A|B_i)$. Зная все вышеперечисленое, несложно по формуле вычислить вероятность успешной сдачи.
\end{Ex}
\\

Формула полной веротяности используется для вычисления априорной вероятности, т.е. вероятности события, которое  еще не произошло.
Пусть теперь \\$\Pro(A) > 0$. Тогда $\Pro(B_i|A)=\frac{\Pro(AB_i)}{\Pro(A)}$. Используя формулу полной вероятности, получаем \underline{формулу Байеса}:
$$\Pro(B_i|A)=\frac{\Pro(A|B_i)\Pro(B_i)}{\sum\limits_{j=1}^n\Pro(A|B_j)\Pro(B_j)}$$

Формула Байеса используется для вычисления апостериорной вероятности. То есть уже известно, что произошло некоторое событие $A$, и нужно вычислить вероятность
того, что произошло некоторое $B_i$. В примере с экзаменом, например, может быть известно, что студент не сдал экзамен, и хочется вычислить вероятность того, что он
сдавал преподавателю <<Р>>.

\newpage
\section{Случайные величины}

\qquad Случайные события "--- это хорошо, но с события типа <<на монетке выпал герб>> плохо формализуемы, а мы хотим формальности и математичности. Поэтому вместо всяких событий хочется работать с числами. Вот этим и займемся. При рассмотрении случайных событий мы ввели вероятностное пространство, которе выглядит так:
$$(\Omega, \Ev, \Pro),$$
где $\Omega$ "--- множество элементарных событий, $\Ev$ "--- $\sigma$-алгебра подмножеств множества элементарных событий, а $\Pro$ "--- вероятность. Мы же будем рассамтривать теперь тройку
$$(\Real, \Bor, \Pro),$$
где $\Real$ "--- действительная прямая, $\Bor$ "--- борелевская $\sigma$-алгебра, а $\Pro$ "--- вероятность. Поясним.

\begin{Def}
\underline{Борелевской $\sigma$-алгеброй} называется минимальная $\sigma$-алгебра, содержащая все открытые подмножества топологического пространства. Элементы борелевской $\sigma$-алгебры называются \underline{борелевскими множествами}.
\end{Def}
\begin{Wtf}
Мы будем рассматривать только топологическое пространство $\Real$, так что это стремное словосочетание можно прямо 
сейчас забыть и понимать открытое множество как открытое множество из матана (все точки внутренние).
\end{Wtf}\\
\begin{Ex}
Покажем, что все <<хорошие>> множества являются Борелевскими.
\begin{enumerate}
\item Все открытые интревалы входят по определению.
\item Отрезок вида $[a, b]$ входит как $\overline{(-\infty, a) \bigcup (b, +\infty)}$.
\item Точка ходит как вырожденный отрезок $[a, a]$.
\item Счетное объединение таких множеств входит по поределению.
\end{enumerate}
\end{Ex}

Теперь формально введем понятие случайной величины (может использоваться сокращение с.в.).

\begin{Def}
Пусть $(\Omega, \Ev, \Pro)$ "--- вероятностное пространство.\\ Тогда \underline{случайной величиной $\xi$} называется функция $\xi : \Omega \to \Real$, измеримая относительно $\Ev$ и $\Bor$. По-другому, $\xi$ "--- случайная величина, если
$$\forall B \in \Bor \quad \xi^{-1}(B) = \lbrace \omega : \xi(\omega) \in B \rbrace \in \Ev$$.
\end{Def}
\begin{Wtf}
Таким финтом ушами мы, по сути, сопоставили каждому событию какое-то <<хорошее>> множество на числовой прямой, и можем рассматривать не вероятности событий, а вероятности попадания в эти <<хорошие>> подмножества числовой прямой.
\end{Wtf}

Введем еще несколько бесполезных определений, которые в дальнейшем использоваться не будут, но знать их не вредно.

\begin{Def}
С каждой случайной величиной свяжем два вероятностных пространства: первое --- $(\Omega, \Ev_\xi, \Pro)$ --- вероятностное пространство, \underline{порожденное $\xi$}. Здесь 
$\Ev_\xi$ - наименьшая $\sigma$-алгебра, для которой выполняется свойство измеримости. Второе --- $(\Real, \Bor, \Pro_\xi)$, где $\Pro_\xi(B) = \Pro(\xi^{-1}(B)) \quad \forall B \in \Bor$ и называется \underline{распределением вероятностей $\xi$}.
\end{Def}

Идем дальше в~сторону упрощения работы со случайностями. Вместо того чтобы рассматривать произвольные борелевские множества, мы будем рассамтривать только множества вида $(-\infty, x)$. Действительно, интервал $(a, b)$ получается из~полупрямых так: $(a, b) = (-\infty, b) \setminus (-\infty, a]$  Таким образом, мы можем рассматривать случайные величины только на таких множествах. Здесь имеется в виду, что для удовлетворения определению случайной величины достаточно измеримости только на
 полупрямых, что следует из следующих свойств полного прообраза: прообраз объединения есть объединение прообразов, прообраз пересечения есть пересечение прообразов,
 прообраз отрицания есть отрицание прообраза. Выше показано, что из полупрямых с помощью этих операций можно получить интервалы, а из интервалов и все $\Bor$.

Теперь несколько полезных утверждений. Пусть $\xi$ --- случайная величина. Тогда $-\xi$ также случайная величина, так как её прообраз от любой полупрямой является
прообразом $\xi$ от симметричной полупрямой, то есть лежит в $\Ev$. $\xi + c$ также будет случайной величиной, поскольку ее прообразом для любой полупрямой будет
прообраз $\xi$ для полупрямой, сдвинутой на $c$, то есть будет лежать в $\Ev$.

\begin{St}
Пусть $\xi, \eta$ --- случайные величины. Тогда множество $\Set{\omega}{\xi(\omega) < \eta(\omega)}$ является событием.
\end{St}
\begin{Proof}
$\Set{\omega}{\xi(\omega) < И\eta(\omega)} = \bigcup\limits_{r \in \mathbb{Q}}\Set{\omega}{\xi(\omega) < r, \eta(\omega) > r}$. 
Заметим, что $\Set{\omega}{\xi(\omega) < r)}$ является событием. Аналогично для $\eta$. Выражение, написанное выше, является счетным объединением пересечений двух событий, то есть событием.
\end{Proof}

Похожими махинациями, а также с использованием этого утверждения, доказывается, что $\xi^2, \xi + \eta, \xi\eta$ являются случайными величинами.
Более того, если $\xi_1, \ldots, \xi_n$ --- с.в., а функция $\phi(x_1, \ldots, x_n)$ является непрерывной на множестве их значений, то $\phi(\xi_1, \ldots, \xi_n)$ будет случайной 
величиной. Это не доказывалось.

\begin{Def}
Рассмотрим вероятностное пространство $(\Omega, \Ev, \Pro)$ и определенную на нем случайную величину $\xi$. Тогда её \underline{функцией распределения $F_\xi(x)$}
 называется функция $F_\xi : \Real \to \Real$
$$F_\xi(x) = \Pro(\omega : \xi(\omega) < x) = \Pro(\xi < x)$$.
\end{Def}

Запись $\Pro(\xi < x)$ является в некотором смысле жаргонной, так как аргументов вероятности должно быть событие из $\Ev$. Но $\xi < x$ мы в дальнейшем будем 
отождествлять с оъединением элементарных событий, образ которых меньше $x$. Из определения случайной величины получаем, что это объединение является событием,
поэтому применение к нему функции вероятности корректно.

Функция распределения (сокращение ф.р.) является очень полезной штукой, поскольку имеет достаточно простой вид и несет в себе всю информацию о распределении, то есть однозначно 
определяет $\Pro_\xi$.

Рассмотрим основные свойства функции распределения:
\begin{enumerate}
	\item $F_\xi(x) \in [0, 1]$
	\item $\lim\limits_{x \to -\infty} F_\xi(x) = 0$
	\item $\lim\limits_{x \to +\infty} F_\xi(x) = 1$
	\item $F_\xi(x)$ монотонно не убывает.
	\item $F_\xi(x)$ непрерывна слева.
\end{enumerate}

Вероятность попадания с.в. в полуинтервал $\Pro_\xi[a,b) = F_\xi(b) - F_\xi(a)$. При стремлении $b \to a$ получим $\Pro(\xi = a) = F_\xi(a+) - F_\xi(a)$, то есть 
вероятность попадания в точку равна скачку функции распределения в этой точке.

\begin{Def}
Точка $x_0$ называется \underline{точкой роста} $F_\xi(x)$, если $\forall \epsilon > 0 \quad \Pro(x_0 - \epsilon \le \xi < x_0 + \epsilon) > 0$
\end{Def}
\begin{Ex}
Это очень полезный пример, который будет использоваться в матстате и который очень любят спрашивать. Пусть $\xi$ --- случайная величина. $\eta = F_\xi(\xi)$. Чему равна
$F_\eta(x)$? По определению $F_\eta(x) = \Pro(\eta < x) = \Pro(F_\xi(\xi) < x)=\Pro(\xi < F_\xi^{-1}(x)) = F_\xi(F_\xi^{-1}(x))=x$. Вообще, тут было бы неплохо 
сказать, что $F_\xi$ непрерывна и строго монотонна, чтобы со спокойной совестью использовать обратную функцию. Таким образом $\eta$ имеет равномерное распределение.
\end{Ex}

\newpage

\section{Понятие меры и интеграла Лебега}

\qquad Мера Лебега вводится потихонечку: сначала для полуинтервала, потом для борелевских множеств, а затем и для всей числовой прямой. Основная идея --- обобщение
понятия длины на страшные, ненормальные множества.

Вспомним сначала аксиомы меры $\mu$ из функана (хех): это функция на множестве $B$ (в нашем случае $[0, 1)$), $\mu \colon B \to \Real$ со свойствами
\begin{enumerate}
	\item $\forall A \in B \quad \mu(A) \ge 0$
	\item $\forall A_1, A_2, \ldots \in B \colon A_iA_j = \varnothing \quad (i \not= j) \Rightarrow \mu(\bigcup\limits_{i=1}^\infty A_i) = \sum\limits_{i=1}^\infty \mu(A_i)$
\end{enumerate} 

Введем сначала меру на борелевских множествах полуинтервала $[0, 1)$, то есть на $\Bor_{[0, 1)}$. Итак, 
\begin{itemize}
	\item На полуинтервалах $(a, b)$ введем меру как $\mu_{[0, 1)}((a, b)) = b - a$
	\item Тогда мера одной точки равна нулю, и мы можем не обращать внимание на концы множеств
	\item Любое конечное объединение, пересечение, отрицание таких интервалов есть конечное объединение интервалов (и, возможно, конечное число точек-концов)
	На них введем меру как сумму мер этих интервалов.
	\item Теперь осталось определить меру на бесконечных объединениях/пересечениях. Для этого воспользуемся теоремой Каратеодори, согласно которой можно продолжить
	меру на $\sigma$-алгебре.
\end{itemize}

Аналогичным образом определим меру $\mu_{[k, k+1)}$ на всех полуинтервалах вида $[k, k+1) \quad (k \in \mathbb{Z})$.
Осталось доопределить меру на всей $\Bor$. $\forall A \in \Bor \quad$
 $$\mu(A)=\sum\limits_{i=-\infty}^{\infty}\mu_{[i, i+1)}(A \bigcap [i, i+1))$$
 
 Теперь введем интеграл \underline{интеграл Лебега} (интеграл по мере Лебега). В отличие от интеграла Римана, где происходит разбиение области определения и выбирается
 значение функции из образа элемента разбиения, в интеграле Лебега разбивается область значений (то есть $Oy$), и некоторое значение из элемента разбиения умножается на
 меру прообраза этого элемента, затем все благополучно складывается. Введем теперь это формально.
 
 Будем рассматривать функции $f \colon \Real \to \Real$ такие, что $\forall c \in \Real \quad \Set{x}{f(x) < c} \in \Bor$, то есть прообразы полупрямых являются
  измеримыми множествами. А как было показано выше, отсюда следует, что прообразы всех борелевских множеств являются измеримыми.
  
  Введем сначала понятие \underline{индикатора}. Индикатор события $A$ - это случайная величина, принимающая значение 1, если событие произошло, и 0 в противном случае.
  Таким образом
  \[
  	\Ind(x) = 
  	\begin{cases}
  		1, x \in A \\
  		0, x \not\in A
  	\end{cases}
  \]
  
 Определим интеграл Лебега на полуинтервале $[0, 1)$
\begin{itemize}
 	\item Пусть функция имеет вид $f(x) = \sum\limits_{i=1}^ky_i \Ind(A_i) \quad (i \not= j \Rightarrow A_iA_j = \varnothing, \ \bigcup_{i=1}^k = [0,1))$. Функции такого вида 		называются \underline{финитными}.  В этом случае
 		$$\int\limits_0^1f(x)\mu(dx) = \sum\limits_{i=1}^k y_i \mu(A_i) $$
	То есть берется мера кусочка, на котором функция принимает значение $y_i$, и умножается на это значение. Получается нечто, напоминающее площадь под графиком.
	\item Пусть теперь $f(x) \ge 0$ на $[0, 1)$. Будем приближать функцию финитной. Возьмем отрезок области значений $[0, n], n \in \mathbb{N}$. Разобьем этот отрезок на
	$n2^n$ кусочков $[\frac{k-1}{2^n}, \frac{k}{2^n}], k = 1, 2, \dots, n2^n$. На каждом кусочке скажем, что значение функции равно $\frac{k-1}{2^n}$. Осталось приблизить 
	$[n, +\infty)$. Будем считать это одной частью, на которой функция принимает значение $n$. Осталось устремить n к бесконечности: тогда, так как размер каждого кусочка первой части равен $\frac{1}{2^n}$, их длина станет бесконечно малой, а та часть, которую мы <<обрубили>> сверху (то есть $[n, +\infty)$), уйдет в бесконечность. Итак,
	$$ \int\limits_0^1 f(x) \mu(dx) = \lim_{n \to \infty}  \biggl[  \sum\limits_{k=1}^{n2^n} \frac{k-1}{2^n} \mu\biggl(\Set{x}{\frac{k-1}{2^n} \le f(x) < \frac{k}{2^n}}\biggl) 
	+ n \mu(\Set{x}{f(x) \ge n})\biggl]$$
	\item Остался случай произвольной функции $f(x)$. Разобьем ее на две: одна функция совпадает с $f(x)$ там, где та положительна, и равняется 0 в остальных случаях,
	другая равна $|f(x)|$ там, где $f(x)$ отрицательна, и 0 иначе. 
	$$ f^+(x) = \max\{0, f(x)\},\quad f^-(x) = -\min\{0, f(x)\}$$
	Для каждой из этих функций интеграл определен по предыдущему пункту. Пользуясь тем, что $f(x) = f^+(x) - f^-(x)$, определим интеграл так:
	$$  \int\limits_0^1 f(x) \mu(dx) =  \int\limits_0^1 f^+(x) \mu(dx) - \int\limits_0^1 f^-(x) \mu(dx) $$
	В случае, если оба интеграла в правой части расходятся, интеграл от $f(x)$ не определен. 
	Так как $|f(x)| = f^+(x) + f^-(x)$, сходимость интеграла Лебега от модуля функции (абсолютная сходимость) эквивалента сходимости интеграла от самой функции
	(то есть обычной сходимости). Это следует из того, что интеграл сходится только в случае конечности обоих интегралов правой части (иначе он не определен), откуда 
	следует конечность их суммы и разности. Таким образом, для интеграла Лебега не существует условно сходящихся функций.
\end{itemize}

	Аналогично вводим интеграл на каждом полуинтервале $[i, i+1), \quad i \in \mathbb{Z}$. Тогда на всей прямой интеграл по множеству $A \subset \Real$ будет определяться так:
	$$ \int\limits_A f(x) \mu(dx) = \sum\limits_{i=-\infty}^{+\infty} \int\limits_{A \bigcap [i, i+1)} f(x) \mu(dx) $$
\begin{Ex}
С помощью интеграла Лебега можно считать интегралы от функций, об интегрировании которых раньше было страшно даже подумать. Например, от функции Дирихле:
  \[
  	D_{[0,1)}(x) = 
  	\begin{cases}
  		1, x \in [0,1) \setminus \mathbb{Q} \\
  		0, x \in \mathbb{Q}
  	\end{cases}
  \]
  Данная функция является финитной, а именно $D_{[0,1)}(x) = \Ind([0,1) \setminus \mathbb{Q})$. Поэтому по первому пунккту
  $$ \int\limits_0^1 D_{[0,1)}(x) \mu(dx) = 1 $$
\end{Ex}

  В дальнейшем $\mu(dx)$ будет опускаться обозначаться просто как $dx$ или $dy$ чтобы подчеркнуть, что считается именно интеграл Лебега.
  
 \newpage
\section{Виды распределений}

Распределения случайных величин можно разделить на 3 типа: непрерывные, дискретные и сингулярные.

\begin{Def}
	Случайная величина $\xi$ называется \underline{абсолютно непрерывной}, если существует интегрируемая функция $p_\xi(x) \ge 0, \ x \in \Real$ такая, что
	функцию распределения $\xi$ является почти всюду (за исключением не более, чем счетного числа точек) дифференцируемой функцией и представима в виде
	$$F_\xi(x) = \int\limits_{-\infty}^x p_\xi(y)dy$$
	Отсюда следует, что функция распределения непрерывна на $\Real$. $p_\xi(x)$ называется \underline{плотностью распределения},
	и почти всюду выполнено $p_\xi(x)=F_\xi'(x)$.
	Плотность, вообще говоря, определена не однозначно.
\end{Def}

\begin{Def}
	Случайная величина $\xi$ называется \underline{дискретной}, если множество точек роста не более, чем счетно, но распределение не является сингулярным, или, 
	другими словами $\exists B = \{x_1, x_2, \ldots\} \colon \Pro(\xi \in B) = 1$.
\end{Def}

\begin{Def}
	Случайная величина $\xi$  называется \underline{сингулярным}, если $F_\xi$ непрерына, и $\exists B \in \Bor \colon \mu(B) = 0, \ \Pro(\xi \in B) = 1$, то есть множество значений случайной величины имеет меру 0, но вероятность попасть в каждую точку этого множества так же нулевая.
\end{Def}

Пара слов о жизненном смысле определений: непрерывная случайная величина имеет областью значений континуальное множество, при это вероятность попасть в отдельно взятую точку нулевая. Пример: равномерное распределение по отрезку. Дискретная случайная величина принимает конечное или счетное множество значений, вследствие этого имеет ступенчатую функцию распределения, например, бросок монетки имеет дискретное распределение. Сингулярное распределение --- это крокодил, который 
не встречается в жизни и будет рассмотрен отдельно.

\begin{St}
	Дискретная случайная величина имеет не более, чем счетное число скачков.
\end{St}
\begin{Proof}
Из свойств функции распределения следует, что дискретная величина имеет не больше двух скачков величины больше $\frac12$. Аналогично, скачков величины больше $\frac13$ не больше 3. То есть скачков величины больше $\frac1n$ не более n. Для любого скачка можно указать $n \in \mathbb{N}$ такое, что величина, этого скачка больше 
$\frac1n$. Значит,каждому скачку можно поставить в соответствие $n$, множество которых счетно. При этом для каждого $n$ существует не более чем счетное число скачков, ему соответсвующих (величины $>\frac1n$). А так как объединение не более, чем счетного числа не более, чем счетных множеств, не более, чем счетно, получаем 
требуемое. 
\end{Proof}\\ \\ \\ \\
\begin{Ex}
Для полного счастья приведем пример сингулярной случайной величины. Пусть функция распределения - так называемая лестница Кантора (см. рисунок).
\parbox[b][3 cm][t]{20mm}{\includegraphics[height=30mm]{kantor}}
\hfill
\parbox[b][3 cm][t]{100mm}{
	Посчитаем меру множества, на котором функция константа, то есть точки этого множества не будут точками роста: сначала это одна ступенька длины 1/3, потом две длины 1/9, и т.д.

}\\
	$$ \frac13 + \frac29 + \frac4{27} = \frac13 \sum\limits_{k=1}^\infty(\frac23)^{k-1} = 1$$
	Тогда множество точек роста имеет меру 0 в силу свойства аддитивности меры.
\end{Ex}
\\

Вообще говоря, существуют менее изысканные примеры сингулярных распределений. Например, при стрельбе из лука в круглую мишень распределение будет сингулярным,
если стрелок попадает только в точки одной прямой. В самом деле, двумерная мера прямой равна 0, как и вероятность попасть в каждую отдельную точку. 

\begin{Th} [Лебега]
	Любую случайную величину можно представить в виде суммы дискретной, абсолютно непрерывной и сингулярной случайной величины. То есть 
	$$ F(x) = \alpha_dF_d(x) + \alpha_cF_c(x) + \alpha_sF_s(x), \quad \alpha_d + \alpha_c + \alpha_s = 1$$
\end{Th}
\begin{Proof}
вышло и не вернулось
\end{Proof}
\end{document}